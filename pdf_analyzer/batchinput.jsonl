{"custom_id": "prompt_1_Test_pdf.pdf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "system", "content": "You are tasked with summarizing research papers focused on development programs and intersectional issues. Belongg, a social organization that prioritizes intersectional inclusion across gender, race, caste, disability, queerness, and indigeneity, needs a clear and comprehensive summary of research papers related to these topics, especially within the context of the Sustainable Development Goals (SDGs). The summary should highlight both problems and solutions related to intersectional inclusion and behavior change.\n\nSummary Structure: The summary should be between 800 and 1000 words and be divided into the following sections:\n1. Topic Overview\n   - Title: Provide the title of the paper.\n   - Authors and Publication Year: Summarize the author(s) and the year of publication.\n   - Focus of the Study: Briefly explain the primary focus of the study and its relevance to intersectional issues.\n   - Intersectional Dimensions: State which intersectional identities (e.g., gender, race, caste, disability) are addressed in the paper.\n   - SDGs Addressed: Identify which SDGs are relevant to the study (e.g., SDG 5: Gender Equality, SDG 10: Reduced Inequalities).\n\n2. Intersectional Challenges and Barriers Identified\n   - Key Barriers: Identify and list the main barriers to achieving inclusion for different marginalized identities (e.g., social norms, structural discrimination, accessibility issues).\n   - Contextual Factors: Describe how these barriers manifest differently for intersectional groups (e.g., how caste and gender interact to create unique challenges).\n   - Stakeholders Affected: Specify which groups are most affected by these barriers (e.g., Indigenous women, LGBTQ+ individuals with disabilities).\n\n3. Solutions and Interventions\n   - Intervention Strategies: Describe the interventions and programs implemented or recommended to overcome these barriers, particularly focusing on solutions that consider multiple identities.\n   - Intersectional Approach: Highlight how the interventions address multiple forms of marginalization and leverage specific strategies for intersectional inclusion.\n   - Behavioral Principles Applied: Identify which behavioral science concepts (e.g., social proof, self-efficacy, norm change) were utilized to address intersectional barriers.\n\n4. Key Findings and Learnings\n   - Effectiveness of Solutions: Summarize whether the interventions were effective, partly effective, or ineffective, and provide evidence or metrics shared in the paper.\n   - Outcomes for Different Identities: Include quantitative results (e.g., % change in behavior) and qualitative insights, noting how the interventions impacted different intersectional identities.\n   - Lessons for Future Programs: Capture the lessons learned, focusing on how future programs can improve inclusivity and address intersectional challenges.\n\nWhere relevant, use bullet points for clarity and easy digestion of information.\n\nExample 1:\n   - Title: \"Influencing Water Conservation Behaviors in Rural India: A Case Study\"\n   - Authors and Publication Year: R. Sharma and S. Gupta, 2021\n   - Program Focus: The paper examines a community-driven initiative aimed at encouraging water conservation behaviors among rural households in Rajasthan, India.\n   - Primary Behavior(s) Addressed: Reducing daily household water consumption and promoting rainwater harvesting practices.\n   - Geographic and Demographic Scope: Rajasthan, India; rural households with a focus on farmers.\n   - Behavioral Barriers Identified:\n     - Awareness Gap: Many households were unaware of the water scarcity problem's severity and its long-term consequences.\n     - Social Norms: Water was perceived as abundant due to deep-rooted cultural norms around resource availability.\n     - Economic Barriers: Initial investments for rainwater harvesting systems were seen as unaffordable.\n   - Solutions and Interventions:\n     - Community Workshops: Engaged local leaders to host workshops on water conservation, creating awareness and a sense of community action.\n     - Commitment Pledges: Households signed public pledges to reduce water usage, leveraging commitment and social accountability.\n     - Financial Support: Subsidies were provided to help install rainwater harvesting units, addressing economic barriers.\n   - Key Findings and Learnings:\n     - Effectiveness: The interventions resulted in a 25% reduction in water usage across participating households.\n     - Qualitative Insight: Many participants reported increased pride in contributing to community welfare.\n     - Lessons for Future Programs: Highlighted the importance of combining financial incentives with community-driven solutions to overcome both economic and cultural barriers.\n\nExample 2:\n   - Title: \"Behavioral Nudges to Promote Handwashing in Schools: Insights from Bangladesh\"\n   - Authors and Publication Year: A. Rahman et al., 2019\n   - Program Focus: This study explores interventions aimed at increasing handwashing with soap among students in primary schools in Bangladesh.\n   - Primary Behavior(s) Addressed: Improving hand hygiene practices among young children.\n   - Geographic and Demographic Scope: Rural and urban schools in Bangladesh; primary school students aged 6-12.\n   - Behavioral Barriers Identified:\n     - Lack of Habit Formation: Handwashing was not an established habit due to inconsistent access to soap and water.\n     - Perceived Invulnerability: Children felt that diseases were not a significant threat, reducing motivation to wash hands.\n     - Peer Influence: Handwashing behavior was inconsistent across peer groups, limiting social reinforcement.\n   - Solutions and Interventions:\n     - Visual Cues: Brightly colored posters with simple handwashing steps were placed near washbasins to serve as constant reminders.\n     - Peer Leaders: Identified and trained student leaders to model good handwashing behavior, utilizing social proof.\n     - Soap Availability: Ensured consistent soap supply through community partnerships, addressing logistical issues.\n   - Key Findings and Learnings:\n     - Effectiveness: Handwashing rates increased by 40% in schools where all interventions were implemented.\n     - Quantitative Outcomes: Incidence of common illnesses (e.g., diarrhea) dropped by 15% over a 6-month period.\n     - Lessons for Future Programs: Emphasized the value of peer-led initiatives to influence behavior change, particularly in school settings.\n"}, {"role": "user", "content": "See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/26798603\nConditions for Intuitive Expertise A Failu re to Disagree\nArticle \u00a0\u00a0 in\u00a0\u00a0Americ an P sychologist  \u00b7 Sept ember 2009\nDOI: 10.1037/ a0016755 \u00a0\u00b7\u00a0Sour ce: PubMed\nCITATIONS\n2,021READS\n19,968\n2 author s, including:\nGary Klein\nShado wBo x LL C & Macr oCognition LL C\n259 PUBLICA TIONS \u00a0\u00a0\u00a022,811  CITATIONS \u00a0\u00a0\u00a0\nSEE PROFILE\nAll c ontent f ollo wing this p age was uplo aded b y Gary Klein  on 25 No vember 2015.\nThe user has r equest ed enhanc ement of the do wnlo aded file.Conditions for Intuitive ExpertiseA Failure to DisagreeDaniel KahnemanPrinceton UniversityGary KleinApplied Research AssociatesThis article reports on an effort to explore the differencesbetween two approaches to intuition and expertise that areoften viewed as con\ufb02icting: heuristics and biases (HB) andnaturalistic decision making (NDM). Starting from theobvious fact that professional intuition is sometimes mar-velous and sometimes \ufb02awed, the authors attempt to mapthe boundary conditions that separate true intuitive skillfrom overcon\ufb01dent and biased impressions. They concludethat evaluating the likely quality of an intuitive judgmentrequires an assessment of the predictability of the environ-ment in which the judgment is made and of the individual\u2019sopportunity to learn the regularities of that environment.Subjective experience is not a reliable indicator of judg-ment accuracy.Keywords:intuition, expertise, overcon\ufb01dence, heuristics,judgmentIn this article we report on an effort to compare ourviews on the issues of intuition and expertise and todiscuss the evidence for our respective positions. Whenwe launched this project, we expected to disagree on manyissues, and with good reason: One of us (GK) has spentmuch of his career thinking about ways to promote relianceon expert intuition in executive decision making and iden-ti\ufb01es himself as a member of the intellectual community ofscholars and practitioners who study naturalistic decisionmaking (NDM). The other (DK) has spent much of hiscareer running experiments in which intuitive judgmentwas commonly found to be \ufb02awed; he is identi\ufb01ed with the\u201cheuristics and biases\u201d (HB) approach to the \ufb01eld.A surprise awaited us when we got together to con-sider our joint \ufb01eld of interest. We found ourselves agree-ing most of the time. Where we initially disagreed, we wereusually able to converge upon a common position. Ourshared beliefs are much more speci\ufb01c than the common-place that expert intuition is sometimes remarkably accu-rate and sometimes off the mark. We accept the common-place, of course, but we also have similar opinions aboutmore speci\ufb01c questions: What are the activities in whichskilled intuitive judgment develops with experience? Whatare the activities in which experience is more likely toproduce overcon\ufb01dence than genuine skill? Because welargely agree about the answers to these questions we alsofavor generally similar recommendations to organizationsseeking to improve the quality of judgments and decisions.In spite of all this agreement, however, we \ufb01nd that we arestill separated in many ways: by divergent attitudes, pref-erences about facts, and feelings about \ufb01ghting words suchas \u201cbias.\u201d If we are to understand the differences betweenour respective communities, such emotions must be takeninto account.We begin with a brief review of the origins andprecursors of the NDM and HB approaches, followed by adiscussion of the most prominent points of contrast be-tween them (NDM: Klein, Orasanu, Calderwood, & Zsam-bok, 1993; HB: Gilovich, Grif\ufb01n, & Kahneman, 2002;Tversky & Kahneman, 1974). Next we present some claimsabout the conditions under which skilled intuitions de-velop, followed by several suggestions for ways to improvethe quality of judgments and choices.Two PerspectivesOrigins of the Naturalistic DecisionMaking ApproachThe NDM approach, which focuses on the successesof expert intuition, grew out of early research on masterchess players conducted by deGroot (1946/1978) and laterby Chase and Simon (1973). DeGroot showed that chessgrand masters were generally able to identify the mostpromising moves rapidly, while mediocre chess playersoften did not even consider the best moves. The chessgrand masters mainly differed from weaker players in theirunusual ability to appreciate the dynamics of complexpositions and quickly judge a line of play as promising orfruitless. Chase and Simon (1973) described the perfor-mance of chess experts as a form of perceptual skill inwhich complex patterns are recognized. They estimatedthat chess masters acquire a repertoire of 50,000 to 100,000immediately recognizable patterns, and that this repertoireenables them to identify a good move without having tocalculate all possible contingencies. Strong players need adecade of serious play to assemble this large collection ofbasic patterns, but of course they achieve impressive levelsDaniel Kahneman, Woodrow Wilson School of Public and InternationalAffairs, Princeton University; Gary Klein, Applied Research Associates,Fairborn, Ohio.We thank Craig Fox, Robin Hogarth, and James Shanteau for theirhelpful comments on earlier versions of this article.Correspondence concerning this article should be addressed to DanielKahneman, Woodrow Wilson School of Public and International Affairs,Princeton University, Princeton, NJ 08544-0001. E-mail: kahneman@princeton.edu515September 2009\u25cfAmerican Psychologist\u00a9 2009 American Psychological Association 0003-066X/09/$12.00Vol. 64, No. 6, 515\u2013526 DOI: 10.1037/a0016755of skill even earlier. On the basis of this work, Simonde\ufb01ned intuition as the recognition of patterns stored inmemory.The early work that led to the approach that is nowcalled NDM was an attempt to describe and analyze thedecision making of commanders of \ufb01re\ufb01ghting companies.Fireground commanders are required to make decisionsunder conditions of uncertainty and time pressure thatpreclude any orderly effort to generate and evaluate sets ofoptions. Klein, Calderwood, and Clinton-Cirocco (1986)investigated how the commanders could make good deci-sions without comparing options. The initial hypothesiswas that commanders would restrict their analysis to onlya pair of options, but that hypothesis proved to be incorrect.In fact, the commanders usually generated only a singleoption, and that was all they needed. They could draw onthe repertoire of patterns that they had compiled duringmore than a decade of both real and virtual experience toidentify a plausible option, which they considered \ufb01rst.They evaluated this option by mentally simulating it to seeif it would work in the situation they were facing\u2014aprocess that deGroot (1946/1978) had described as progres-sive deepening. If the course of action they were consid-ering seemed appropriate, they would implement it. If ithad shortcomings, they would modify it. If they could noteasily modify it, they would turn to the next most plausibleoption and run through the same procedure until an accept-able course of action was found. This recognition-primeddecision (RPD) strategy was effective because it took ad-vantage of the commanders\u2019 tacit knowledge (Klein et al.,1986). The \ufb01reground commanders were able to draw ontheir repertoires to anticipate how \ufb02ames were likely tospread through a building, to notice signs that a house waslikely to collapse, to judge when to call for additionalsupport, and to make many other critical decisions. TheRPD model is consistent with the work of deGroot (1946/1978) and Simon (1992) and has been replicated in multi-ple domains, including system design, military commandand control, and management of offshore oil installations(see Klein, 1998, for a review). In each of these domains,the RPD model offers a generally encouraging picture ofexpert performance. It would be a caricature of the NDMapproach, however, to describe it as being solely dedicatedto praising expertise. NDM researchers have also tried todocument and analyze failures in the performance of ex-perts (Cannon-Bowers & Salas, 1998; Klein, 1998; Woods,O\u2019Brien, & Hanes, 1987). In fact, the NDM movement wascrystallized by an event that resulted from a catastrophicfailure in expert decision making.In 1988, an international tragedy occurred after theUSSVincennesaccidentally shot down an Iranian Airbus(Fogarty, 1988). The USSVincenneswas an Aegis cruiser,one of the most technologically advanced systems in theNavy inventory, but the technology was not suf\ufb01cient tostave off the disaster. The incident has been the subject ofdetailed investigation by NDM researchers (Collyer &Malecki, 1998; Klein, 1998). As a result of the disastrouserror and subsequent political fallout, the U.S. Navy de-cided to initiate a program of research on decision making,the Tactical Decision Making Under Stress (TADMUS)program (Cannon-Bowers & Salas, 1998).Thus it was that in 1989 a group of 30 researchers whostudied decision making in natural settings met for severaldays in an effort to \ufb01nd commonalities between the deci-sion-making processes of \ufb01re\ufb01ghters, nuclear power plantcontrollers, Navy of\ufb01cers, Army of\ufb01cers, highway engi-neers, and other populations. Several researchers from thejudgment and decision making tradition participated in thismeeting and in the preparation of a book describing theNDM perspective (Klein et al., 1993). Lipshitz (1993)identi\ufb01ed several decision-making models that were devel-oped to describe the strategies used in \ufb01eld settings, in-cluding the recognition-primed decision model (Klein,1993), the cognitive continuum model (Hammond, Hamm,Grassia, & Pearson, 1987), image theory (Beach, 1990), thesearch for dominance structures (Montgomery, 1993), andthe skills/rules/knowledge framework and decision ladder(Rasmussen, 1986). The NDM movement that emergedfrom this meeting focuses on \ufb01eld studies of subject-matterexperts who make decisions under complex conditions.These experts are expected to successfully attain vaguelyde\ufb01ned goals in the face of uncertainty, time pressure, highstakes, team and organizational constraints, shifting condi-tions, and action feedback loops that enable people tomanage disturbances while trying to diagnose them(Orasanu & Connolly, 1993).A central goal of NDM is to demystify intuition byidentifying the cues that experts use to make their judg-ments, even if those cues involve tacit knowledge and aredif\ufb01cult for the expert to articulate. In this way, NDMresearchers try to learn from expert professionals. ManyNDM researchers use cognitive task analysis (CTA) meth-ods to investigate the cues and strategies that skilled deci-\nDanielKahneman\n516 September 2009\u25cfAmerican Psychologistsion makers apply (Crandall, Klein, & Hoffman, 2006;Schraagen, Chipman, & Shalin, 2000). CTA methods aresemi-structured interview techniques that elicit the cuesand contextual considerations in\ufb02uencing judgments anddecisions. Researchers cannot expect decision makers toaccurately explain why they made decisions (Nisbett &Wilson, 1977); CTA methods provide a basis for makinginferences about the judgment and decision process. Forexample, Crandall and Getchell-Reiter (1993) studiednurses in a neonatal intensive care unit (NICU) who coulddetect infants developing life-threatening infections evenbefore blood tests came back positive. When asked, thenurses were at \ufb01rst unable to describe how they made theirjudgments. The researchers used CTA methods to probespeci\ufb01c incidents and identi\ufb01ed a range of cues and pat-terns, some of which had not yet appeared in the nursing ormedical literature. A few of these cues were opposite to theindicators of infection in adults. Crandall and Gamblian(1991) extended the NICU work. They con\ufb01rmed the \ufb01nd-ings with nurses from a different hospital and then createdan instructional program to help new NICU nurses learnhow to identify the early signs of sepsis in neonates. Thatprogram has been widely disseminated throughout thenursing community.Origins of the Heuristics and Biases ApproachIn sharp contrast to NDM, the HB approach favors askeptical attitude toward expertise and expert judgment.The origins of this attitude can be traced to a famousmonograph published by Paul Meehl in 1954. Meehl(1954) reviewed approximately 20 studies that comparedthe accuracy of forecasts made by human judges (mostlyclinical psychologists) and those predicted by simple sta-tistical models. The criteria in the studies that Meehl (1954)discussed were diverse, with outcome measures rangingfrom academic success to patient recidivism and propensityfor violence. Although the algorithms were based on asubset of the information available to the clinicians, statis-tical predictions were more accurate than human predic-tions in almost every case. Meehl (1954) believed that theinferiority of clinical judgment was due in part to system-atic errors, such as the consistent neglect of the base ratesof outcomes in discussion of individual cases. In a well-known article, he later explained his reluctance to attendclinical conferences by citing his annoyance with the cli-nicians\u2019 uncritical reliance on their intuition and their fail-ure to apply elementary statistical reasoning (Meehl, 1973).Inconsistency is a major weakness of informal judg-ment: When presented with the same case information onseparate occasions, human judges often reach differentconclusions. Goldberg (1970) reported a \u201cbootstrappingeffect,\u201d which provides the most dramatic illustration of theeffect of inconsistency on the validity of judgments. Gold-berg required a group of 29 clinicians to make diagnosticjudgments (psychotic vs. neurotic) in a set of cases, basedon personality test pro\ufb01les of 861 patients who had beenindependently assigned to one of these categories. He con-structed an individual model of the predictions of eachjudge\u2014using multiple regression to estimate the weightsthat the judge assigned to each of the 11 scales in theMinnesota Multiphasic Personality Inventory. Judges werethen required to make predictions for a new set of cases;Goldberg also used the individual statistical model of eachjudge to generate a prediction for these new cases. Thebootstrap models were almost always more accurate thanthe judges they modeled. The only plausible explanation ofthis remarkable result is that human judgments are noisy toan extent that substantially impairs their validity. In anextensive meta-analysis of judgment studies using the lensmodel, Karelaia and Hogarth (2008) reported strong sup-port for the generality of the bootstrap effect and for thecrucial importance of lack of consistency in explaining thiseffect.Kahneman read Meehl\u2019s book in 1955 while servingin the Psychological Research Unit of the Israel DefenseForces, and the book helped him make sense of his ownencounters with the dif\ufb01culties of clinical judgment. One ofKahneman\u2019s duties was to assess candidates for of\ufb01certraining, using \ufb01eld tests and other observations as well asa personal interview. Kahneman (2003) described the pow-erful sense of getting to know each candidate and theaccompanying conviction that he could foretell how wellthe candidate would do in further training and eventually incombat. The subjective conviction of understanding eachcase in isolation was not diminished by the statisticalfeedback from of\ufb01cer training school, which indicated thatthe validity of the assessments was negligible. Kahnemancoined the termillusion of validityfor the unjusti\ufb01ed senseof con\ufb01dence that often comes with clinical judgment. Hisearly experience with the fallibility of intuitive impressionscould hardly be more different from Klein\u2019s formativeencounter with the successful decision making of \ufb01re-ground commanders.\nGary Klein\n517September 2009\u25cfAmerican PsychologistThe \ufb01rst study in the HB tradition was conducted in1969 (Tversky & Kahneman, 1971). It described perfor-mance in a task that researchers often perform withoutrecourse to computation: choosing the number of cases fora psychological experiment. The participants in the studywere sophisticated methodologists and statisticians, includ-ing two authors of statistics textbooks. They answeredrealistic questions about the sample size they consideredappropriate in different situations. The conclusion of thestudy was that sophisticated scientists reached incorrectconclusions and made inferior choices when they followedtheir intuitions, failing to apply rules with which they werecertainly familiar. The article offered a strongly wordedrecommendation that researchers faced with the task ofchoosing a sample size should forsake intuition in favor ofcomputation. This initial study of professionals reinforcedTversky and Kahneman (1971) in their belief (originallybased on introspection) that faulty statistical intuitions sur-vive both formal training and actual experience. Manystudies in the intervening decades have con\ufb01rmed the per-sistence of a diverse set of intuitive errors in the judgmentsof some professionals.Contrasts Between the NaturalisticDecision Making and Heuristicsand Biases ApproachesThe intellectual traditions that we have traced to deGroot\u2019s(1946/1978) studies of chess masters (NDM) and to Meehl\u2019s(1954) research on clinicians (HB) are alive and well today.They are re\ufb02ected in the approaches of our respective intel-lectual communities. In this section we consider three impor-tant contrasts between the two approaches: the stance taken bythe NDM and HB researchers toward expert judgment, the useof \ufb01eld versus laboratory settings for decision-making re-search, and the application of different standards of perfor-mance, which leads to different conclusions about expertise.Stance Regarding Expertise andDecision AlgorithmsThere is no logical inconsistency between the observationsthat inspired the NDM and HB approaches to professionaljudgment: The intuitive judgments of some professionalsare impressively skilled, while the judgments of otherprofessionals are remarkably \ufb02awed. Although not contra-dictory, these core observations suggest con\ufb02icting gener-alizations about the utility of expert judgment. Members ofthe HB community are of course aware of the existence ofskill and expertise, but they tend to focus on \ufb02aws inhuman cognitive performance. Members of the NDM com-munity know that professionals often err, but they tend tostress the marvels of successful expert performance.The basic stance of HB researchers, as they considerexperts, is one of skepticism. They are trained to look foropportunities to compare expert performance with perfor-mance by formal models or rules and to expect that expertswill do poorly in such comparisons. They are predisposedto recommend the replacement of informal judgment byalgorithms whenever possible. Researchers in the NDMtradition are more likely to adopt an admiring stance to-ward experts. They are trained to explore the thinking ofexperts, hoping to identify critical features of the situationthat are obvious to experts but invisible to novices andjourneymen, and then to search for ways to pass on theexperts\u2019 secrets to others in the \ufb01eld. NDM researchers aredisposed to have little faith in formal approaches becausethey are generally skeptical about attempts to impose uni-versal structures and rules on judgments and choices thatwill be made in complex contexts.We found that the sharpest differences between thetwo of us were emotional rather than intellectual. AlthoughDK is thrilled by the remarkable intuitive skills of expertsthat GK and others have described, he also takes consid-erable pleasure in demonstrations of human folly and in thecomeuppance of overcon\ufb01dent pseudo-experts. For hispart, GK recognizes that formal procedures and algorithmssometimes outdo human judgment, but he enjoys hearingabout cases in which the bureaucratization of decisionmaking fails. Further, the nonoverlapping sets of col-leagues with whom we interact generally share our atti-tudes and reinforce our differences. Nevertheless, as thisarticle shows, we agree on most of the issues that matter.Field Versus LaboratoryThere is an obvious difference in the primary form of researchconducted by the respective research communities. The mem-bers of the HB community are mostly based in academicdepartments, and they tend to favor well-controlled experi-ments in the laboratory. The members of the NDM commu-nity are typically practitioners who operate in \u201creal-world\u201dorganizations. They have a natural sympathy for the ecolog-ical approach, \ufb01rst popularized in the late 1970s, which ques-tions the relevance of laboratory experiments to real-worldsituations. NDM researchers use methods such as cognitivetask analysis and \ufb01eld observation to investigate judgmentsand decision making under complex conditions that would bedif\ufb01cult to recreate in the laboratory.There is no logically necessary connection between thesemethodological choices and the nature of the hypotheses andmodels being tested. As the examples of the preceding sectionillustrate, the view that heuristics and biases are only studiedand found in the laboratory is a caricature.1Similarly, theRPD model could have emerged from the laboratory, and ithas been tested there (Johnson & Raab, 2003; Klein, Wolf,Militello, & Zsambok, 1995). In addition, a number of NDMresearchers have reported studies of the performance of pro-\ufb01cient decision makers in realistically simulated environments(e.g., Smith, Gif\ufb01n, Rockwell, & Thomas, 1986).1Among many other examples, see Slovic (2000) for applications tothe study of responses to risk; Guthrie, Rachlinski, and Wistrich (2007)and Sunstein (2000) for applications in the legal domain; Croskerry andNorman (2008) for medical judgment; Bazerman (2005) for managerialjudgments and decision making; and Kahneman and Renshon (2007) forpolitical decision making. The collection assembled by Gilovich, Grif\ufb01n,and Kahneman (2002) includes other examples.518 September 2009\u25cfAmerican PsychologistThe Definition of ExpertiseNDM researchers cannot use the same kinds of optimalitycriteria as the HB community to de\ufb01ne expertise. In rarecases (e.g., the ratings of chess players based on theirrecord of wins and losses against other rated players) theperformance level of experts is determined using standard-ized measures. However, in most of the situations studiedby NDM researchers, the criteria for judging expertise arebased on a history of successful outcomes rather than onquantitative performance measures. The most commonmethod for de\ufb01ning expertise in NDM research is to rely onpeer judgments. The conditions for de\ufb01ning expertise arethe existence of a consensus and evidence that the consen-sus re\ufb02ects aspects of successful performance that areobjective even if they are not quanti\ufb01ed explicitly. If theperformance of different professionals can be compared,the best practitioners de\ufb01ne the standard. As Shanteau(1992) suggested, \u201cExperts are operationally de\ufb01ned asthose who have been recognized within their profession ashaving the necessary skills and abilities to perform at thehighest level\u201d (p. 255). For example, captains of \ufb01re\ufb01ght-ing companies are evaluated not only by their ability toextinguish \ufb01res, but also by other criteria, such as theamount of damage created before the \ufb01re is controlled.When colleagues say, \u201cIf Person X had been there insteadof Person Y, the \ufb01re would not have spread as far,\u201d thenPerson X counts as an expert within that organization. Theuse of peer judgments can distinguish highly competentdecision makers from mediocre ones who may have thesame amount of experience and from novices who havelittle experience. This level of differentiation is suf\ufb01cientfor most NDM studies.In several of the studies that Meehl (1954) reviewed,the quality of expert performance was evaluated by com-paring the accuracy of decisions made by experts with theaccuracy of optimal linear combinations. If the predictionsgenerated by a linear combination of a few variables aremore accurate (in a new sample) than those of a profes-sional who has access to the same information, the perfor-mance of the professional is certainly suboptimal. Note thatthe optimality criterion is signi\ufb01cantly more demandingthan the criteria by which expertise is evaluated in NDMresearch. NDM researchers compare the performance ofprofessionals with that of the most successful experts intheir \ufb01eld, whereas HB researchers prefer to compare thejudgments of professionals with the outcome of a modelthat makes the best possible use of available information. Itis entirely possible for the predictions of experienced cli-nicians to be superior to those of novices but inferior to alinear model or an intelligent system.Sources of IntuitionThe judgments and decisions that we are most likely to callintuitive come to mind on their own, without explicitawareness of the evoking cues and of course without anexplicit evaluation of the validity of these cues. The \ufb01re-\ufb01ghter feels that the house is very dangerous, the nursefeels that an infant is ill, and the chess master immediatelysees a promising move. Intuitive skills are not restricted toprofessionals: Anyone can recognize tension or fatigue in afamiliar voice on the phone. In the language of the two-system (or dual process) models that have recently becomepopular (Evans & Frankish, 2009; see Evans, 2007, for areview of the origins of these ideas), intuitive judgmentsare produced by \u201cSystem 1 operations,\u201d which are auto-matic, involuntary, and almost effortless. In contrast, thedeliberate activities of System 2 are controlled, voluntary,and effortful\u2014they impose demands on limited attentionalresources. System 2 is involved, for example, when oneperforms a calculation (17/H1100324/H11005?), completes a taxform, reads a map, makes a left turn into heavy traf\ufb01c, orparks in a narrow space. Self-monitoring is also a System2 operation, which is impaired by concurrent effortfultasks.The distinction between Systems 1 and 2 plays animportant role in both the HB and NDM approaches. In theRPD model, for example, the performance of experts in-volves both an automatic process that brings promisingsolutions to mind and a deliberate activity in which theexecution of the candidate solution is mentally simulated ina process of progressive deepening. In the HB approach,System 2 is involved in the effortful performance of somereasoning and decision-making tasks as well as in thecontinuous monitoring of the quality of reasoning. Whenthere are cues that an intuitive judgment could be wrong,System 2 can impose a different strategy, replacing intu-ition by careful reasoning.2The NDM and HB approaches share the assumptionthat intuitive judgments and preferences have the charac-teristics of System 1 activity: They are automatic, ariseeffortlessly, and often come to mind without immediatejusti\ufb01cation. However, the two approaches focus on differ-ent classes of intuition. Intuitive judgments that arise fromexperience and manifest skill are the province of NDM,which explores the cues that guided such judgments and theconditions for the acquisition of skill. In contrast, HBresearchers have been mainly concerned with intuitivejudgments that arise from simplifying heuristics, not fromspeci\ufb01c experience. These intuitive judgments are lesslikely to be accurate and are prone to systematic biases.We discuss the two classes of judgment in sequence.First, we describe the process of skill acquisition thatsupports the intuitive judgments and preferences of genuineexperts. In particular, we explore two necessary conditionsfor the development of skill: high-validity environmentsand an adequate opportunity to learn them. Next, we dis-cuss heuristic-based intuitions and some of the biases towhich they are prone. Finally, we address the question ofthe critique of intuition: How can skilled intuitions bedistinguished from heuristic-based intuitions?2The contrast between System 1 and System 2 has given rise to itsown literature. For example, J. St. B. T. Evans (2007) has asserted thatSystem 1 is affected by the tendency to contextualize problems in the lightof prior knowledge and belief and that System 2 is affected by thetendency to satis\ufb01ce without considering alternatives.519September 2009\u25cfAmerican PsychologistSkilled Intuition as RecognitionSimon (1992) offered a concise de\ufb01nition of skilled intu-ition that we both endorse: \u201cThe situation has provided acue: This cue has given the expert access to informationstored in memory, and the information provides the answer.Intuition is nothing more and nothing less than recognition\u201d(p. 155). The model of intuition as recognition is helpful inseveral ways. First, it demysti\ufb01es intuition. Many expertswho have intuitions (and some authors who study them)endow intuition with an almost magic aura\u2014knowledgethat is not acquired by a rational process. In Simon\u2019sde\ufb01nition, the process by which the pediatric nurse recog-nizes that an infant may be gravely ill is not different inprinciple from the process by which she would notice thata friend looks tired or angry or from the way in which asmall child recognizes that an animal is a dog, not a cat. Itmay be worth noting that this description of pattern recog-nition and the skilled pattern recognition described in theRPD model are different from the recognition heuristicdiscussed by Goldstein and Gigerenzer (1999), which is aspecial-purpose rule of thumb.The recognition model implies two conditions thatmust be satis\ufb01ed for an intuitive judgment (recognition) tobe genuinely skilled: First, the environment must provideadequately valid cues to the nature of the situation. Second,people must have an opportunity to learn the relevant cues.For the \ufb01rst condition, valid cues must be speci\ufb01able, atleast in principle\u2014even if the individual does not knowwhat they are. The child relies on valid cues to identify adog, without any ability to state what the cues are. Simi-larly, the nurse and the \ufb01re\ufb01ghter are also guided by validcues they \ufb01nd in the environment. No magic is involved. Acrucial conclusion emerges: Skilled intuitions will onlydevelop in an environment of suf\ufb01cient regularity, whichprovides valid cues to the situation. The ways in whichskilled judgments take advantage of environmental regu-larities have been discussed by, among others, Brunswik(1957) and Hertwig, Hoffrage, and Martingnon (1999).Validity, as we use the term, describes the causal andstatistical structure of the relevant environment. For exam-ple, it is very likely that there are early indications that abuilding is about to collapse in a \ufb01re or that an infant willsoon show obvious symptoms of infection. On the otherhand, it is unlikely that there is publicly available informa-tion that could be used to predict how well a particularstock will do\u2014if such valid information existed, the priceof the stock would already re\ufb02ect it. Thus, we have morereason to trust the intuition of an experienced \ufb01regroundcommander about the stability of a building, or the intui-tions of a nurse about an infant, than to trust the intuitionsof a trader about a stock. We can con\ufb01dently expect that adetailed study of how professionals think is more likely toreveal useful predictive cues in the former cases than in thelatter.Determining the validity of an environment is notalways easy. When Tetlock (2005) embarked on his ambi-tious study of long-term forecasts of strategic and eco-nomic events by experts, the outcome of his research wasnot obvious. Fifteen years later it was quite clear that thehighly educated and experienced experts that he studiedwere not superior to untrained readers of newspapers intheir ability to make accurate long-term forecasts of polit-ical events. The depressing consistency of the experts\u2019failure to outdo the novices in this task suggests that theproblem is in the environment: Long-term forecasting mustfail because large-scale historical developments are toocomplex to be forecast. The task is simply impossible. Athought experiment can help. Consider what the history ofthe 20th century might have been if the three fertilized eggsthat became Hitler, Stalin, and Mao had been female. Thecentury would surely have been very different, but can oneknow how?In other environments, the regularities that can beobserved are misleading. Hogarth (2001) introduced theuseful notion of wicked environments, in which wrongintuitions are likely to develop. His most compelling ex-ample (borrowed from Lewis Thomas) is the early 20th-century physician who frequently had intuitions about pa-tients in the ward who were about to develop typhoid. Hecon\ufb01rmed his intuitions by palpating these patients\u2019tongues, but because he did not wash his hands the intui-tions were disastrously self-ful\ufb01lling.High validity does not imply the absence of uncer-tainty, and the regularities that are to be discovered aresometimes statistical. Games such as bridge or poker countas high-validity situations. The mark of these situations isthat skill, the ability to identify favorable bets, improveswithout guaranteeing that every attempt will succeed. Thechallenge of learning bridge and poker is not essentiallydifferent from the challenge of learning chess, where theuncertainty arises from the enormous number of possibledevelopments.As the examples of competitive games illustrate, thesecond necessary condition for the development of recog-nition (and of skilled intuition) is an adequate opportunityto learn the relevant cues. It has been estimated that chessmasters must invest 10,000 hours to acquire their skills(Chase & Simon, 1973). Fortunately, most of the skills canbe acquired with less practice. A child does not needthousands of examples to learn to discriminate dogs fromcats. The skilled pediatric nurse has seen a suf\ufb01cient num-ber of sick infants to recognize subtle signs of disease, andthe experienced \ufb01reground commander has experiencednumerous \ufb01res and probably imagined many more, duringyears of thinking and conversing about \ufb01re\ufb01ghting. With-out these opportunities to learn, a valid intuition can onlybe due to a lucky accident or to magic\u2014and we do notbelieve in magic.Two conditions must be satis\ufb01ed for skilled intuitionto develop: an environment of suf\ufb01ciently high validity andadequate opportunity to practice the skill. Ericsson, Char-ness, Hoffman, and Feltovich (2006) have described arange of factors that in\ufb02uence the rate of skill development.These include the type of practice people employ, theirlevel of engagement and motivation, and the self-regula-tory processes they use. Even when the circumstances arefavorable, however, some people will develop skilled in-520 September 2009\u25cfAmerican Psychologisttuitions more quickly than others. Talent surely matters.Every normal child can recognize a cat or a dog, but not alldedicated chess players become grand masters. Extraordi-nary players such as Fischer and Kasparov were able torecognize patterns that other grand masters could not see ontheir own\u2014although the weaker players could recognizethe validity of the star\u2019s intuition when led through it.Intuitions that are available only to a few exceptionalindividuals are often called creative. Like other intuitions,however, creative intuitions are based on \ufb01nding validpatterns in memory, a task that some people perform muchbetter than others. There are large individual differences inperformance on the Remote Associations Test (RAT),which has a long history as a test of creativity. Participantsin that test are instructed to search for a common associateof three words. The task has a wide range of dif\ufb01culty: Theitem cottage/swiss/cake is easy, but few people can quickly\ufb01nd the answer to the item dive/light/rocket\u2014althougheveryone recognizes the answer as valid (it is above us andis blue in good weather; Mednick, 1962). The RAT bringsus back to Simon\u2019s observation that the regularities onwhich intuitions depend are represented in memory. Thesituation of the RAT has high validity: Widely sharedpatterns of associations exist, which everyone can recog-nize although few can \ufb01nd them without prompting.Imperfect IntuitionWe have seen that reliably skilled intuitions are likely todevelop when the individual operates in a high-validityenvironment and has an opportunity to learn the rules ofthat environment. These conditions often remain unmet inprofessional contexts, either because the environment isinsuf\ufb01ciently predictable (as in the long-term forecasting ofpolitical events) or because of the absence of opportunitiesto learn its rules (as in the case of \ufb01re\ufb01ghters exposed to a\ufb01re in a skyscraper with unexpected damage to the heatshielding of its structural support). We both agree that mostof the intuitive judgments and decisions that System 1produces are skilled, appropriate, and eventually success-ful. But we also agree that not all intuitive judgments areskilled, although our hunches about the frequency of ex-ceptions differ. People, including experienced profession-als, sometimes have subjectively compelling intuitionseven when they lack true skill, either because the environ-ment is insuf\ufb01ciently regular or because they have notmastered it. Lewis (2003) described the weaknesses in theability of baseball scouts and managers to judge the capa-bilities, contributions, and potential of players. Despiteample opportunities to acquire judgment skill, scouts andmanagers were often insensitive to important variables andoverly in\ufb02uenced by such factors as the player\u2019s appear-ance\u2014a clear case of prediction by representativeness.When intuitive judgments do not come from skill,where do they come from? This is the question that stu-dents of heuristics and biases have explored, mostly inlaboratory experiments. The answer, of course, is thatincorrect intuitions, like valid ones, also arise from theoperations of memory. Three phenomena that have beendiscussed in the HB literature illustrate the sources of\ufb02awed intuitive judgments.Frederick (2005) has studied problems such as thefollowing: \u201cA ball and a bat together cost $1.10. The batcosts a dollar more than the ball. How much does the ballcost?\u201d The question invariably evokes an immediate tenta-tive solution: 10 cents. But the intuitive response is wrongin this problem: The correct response is 5 cents. Further-more, an easy check will quickly show that the answer iswrong: If the ball is worth 10 cents, then the bat is worth$1.10 and the total is $1.20, which is not correct. Thesurprising \ufb01nding of Frederick\u2019s research is that manyintelligent people adopt the intuitively compelling responsewithout checking it. The incidence of intuitive errors in thisquestion ranges from approximately 50% in top undergrad-uate schools (MIT, Princeton, Harvard) to 90% in some-what less selective schools. It can be argued that the settingof this problem is not typical of the challenges that peopleface in the real world, but the phenomenon that Frederickstudied is hardly restricted to puzzles. A common genre ofbusiness literature celebrates successful leaders who madestrategic decisions on the basis of gut feelings and intui-tions that they did not adequately check, but many of thesesuccesses owe more to luck than to genius (Rosenzweig,2007).The anchoring phenomenon is another case in which abias in the operations of memory causes intuitions to goastray. Suppose some participants in an experiment are \ufb01rstasked \u201cIs the average price of German cars more or lessthan $100,000?\u201d before they are required to provide anumerical estimate of the average cost of German cars.Other respondents encounter a different anchoring ques-tion: They are \ufb01rst asked whether the average cost ofGerman cars is more or less than $30,000, and then they areto give an estimate of the average. We can expect theestimates of the two groups to differ by as much as half thedifference between the anchors\u2014in this case the expectedanchoring effect would be $35,000 (Jacowitz & Kahneman,1995). The mechanism of anchoring is well understood(Mussweiler & Strack, 2000). The original question withthe high anchor brings expensive cars to the respondents\u2019mind: Mercedes, BMWs, Audis. The lower anchor is morelikely to evoke the image of a beetle and the name Volks-wagen. The initial question therefore biases the sample ofcars that come to mind when people next attempt to esti-mate the average price of German cars. The process ofestimating the average is a deliberate, System 2 operation,but the bias occurs in the automatic phase in which in-stances are retrieved from memory. The resulting anchor-ing effect is large and robust. The answers that come tomind are typically held with substantial con\ufb01dence, and thevictims of anchoring manipulations con\ufb01dently deny anyeffect of the anchor. The common criticism of laboratoryexperiments hardly applies here, because large anchoringeffects have been demonstrated in the courtroom, in realestate transactions, and in other real-world contexts.For a \ufb01nal example, consider this question: \u201cJulie is agraduating senior. She read \ufb02uently at age 4. What is yourbest guess of her GPA [grade point average]?\u201d Most people521September 2009\u25cfAmerican Psychologistwho think about this question report having an immediateintuitive impression of the best-\ufb01tting GPA. The value thatcomes to their mind is a GPA that is as impressive asJulie\u2019s precocity in reading\u2014roughly a match of percentilescores. This intuitive prediction is clearly wrong because itis not regressive. The correlation between early reading andgraduating GPA is not high and certainly does not justifynonregressive matching. The process that generates thisintuitive answer has been called attribute substitution. Theattribute that is to be assessed is GPA, but the answer issimply a projection onto the GPA scale of an evaluation ofreading precocity. Attribute substitution has been describedas an automatic process. It produces intuitive judgments inwhich a dif\ufb01cult question is answered by substituting aneasier one\u2014the essence of heuristic thinking (Kahneman &Frederick, 2002).Of course, the mechanisms that produce incorrectintuitions will only operate in the absence of skill. If peoplehave a skilled response to the task with which they arecharged, they will apply their skill. But even in the absenceof skill an intuitive response may come to their minds. Thedif\ufb01culty is that people have no way to know where theirintuitions came from. There is no subjective marker thatdistinguishes correct intuitions from intuitions that are pro-duced by highly imperfect heuristics. An important char-acteristic of intuitive judgments, which they share withperceptual impressions, is that a single response initiallycomes to mind. Most of the time we have to trust this \ufb01rstimpulse, and most of the time we are right or are able tomake the necessary corrections if we turn out to be wrong,but high subjective con\ufb01dence is not a good indication ofvalidity (Einhorn & Hogarth, 1978). Checking one\u2019s intu-ition is an effortful operation of System 2, which people donot always perform\u2014sometimes because it is dif\ufb01cult to doso and sometimes because they do not bother.Intuitions that originate in heuristics are not necessar-ily wrong. Indeed, the original statement of the HB ap-proach asserted, \u201cIn general these heuristics are quite use-ful, but sometimes they lead to severe and systematicerrors\u201d (Tversky & Kahneman, 1974, p. 1124). The HBclaim is not that intuitions that arise in heuristics are alwaysincorrect, only that they are less trustworthy than intuitionsthat are rooted in speci\ufb01c experiences. Unfortunately, peo-ple are not normally aware of the origins of the thoughtsthat come to their minds, and the correlation between theaccuracy of their judgments and the con\ufb01dence they expe-rience is not consistently high (Arkes, 2001; Grif\ufb01n &Tversky, 1992). Subjective con\ufb01dence is often determinedby the internal consistency of the information on which ajudgment is based, rather than by the quality of that infor-mation (Einhorn & Hogarth, 1978; Kahneman & Tversky,1973). As a result, evidence that is both redundant and\ufb02imsy tends to produce judgments that are held with toomuch con\ufb01dence. These judgments will be presented tooassertively to others and are likely to be believed more thanthey deserve to be. The safe way to evaluate the probableaccuracy of a judgment (our own or someone else\u2019s) is byconsidering the validity of the environment in which thejudgment was made as well as the judge\u2019s history oflearning the rules of that environment.Professional IntuitionsWe are of course not the \ufb01rst to have identi\ufb01ed a regularenvironment and an adequate opportunity to learn it aspreconditions for the development of skills, including in-tuitive skills (see, e.g., Hogarth, 2001). Other investigatorshave focused on attitude, motivation, talent, and deliberatepractice as crucial to skill development (Ericsson, 2006;Ericsson et al., 2006).The importance of predictable environments and op-portunities to learn them was apparent in an early review ofprofessions in which expertise develops. Shanteau (1992)reviewed evidence showing that expertise was found inlivestock judges, astronomers, test pilots, soil judges, chessmasters, physicists, mathematicians, accountants, grain in-spectors, photo interpreters, and insurance analysts. In con-trast, Shanteau noted poor performance by experiencedprofessionals in another large set of occupations: stockbro-kers, clinical psychologists, psychiatrists, college admis-sions of\ufb01cers, court judges, personnel selectors, and intel-ligence analysts. Shanteau searched for task characteristicsthat distinguished the domains in which experts did wellfrom those in which experts did poorly. The factors that weidenti\ufb01ed\u2014the predictability of outcomes, the amount ofexperience, and the availability of good feedback\u2014wereincluded in his list. In addition, Shanteau pointed to static(as opposed to dynamic) stimuli as favorable to goodperformance.Three professions\u2014nurses, physicians, and audi-tors\u2014appeared on both of Shanteau\u2019s (1992) lists. Theseprofessionals exhibited genuine expertise in some of theiractivities but not in others. We refer to such mixed gradesfor professionals as \u201cfractionated expertise,\u201d and we be-lieve that the fractionation of expertise is the rule, not anexception. For example, auditors who have expertise in\u201chard\u201d data such as accounts receivable may do much lesswell with \u201csoft\u201d data such as indications of fraud (J. Shan-teau, personal communication, February 12, 2009).There are a few activities, such as chess, in which amaster will not encounter challenges that are genuinelynew. In most domains, however, professionals will occa-sionally have to deal with situations and tasks that theyhave not had an opportunity to master. Physicians, as iswell known, encounter from time to time diagnostic prob-lems that are entirely new to them\u2014they have expertise insome diagnoses but not in others. Similarly, weather fore-casters are more successful in the routine prediction oftemperature and precipitation than in forecasting hail(Stewart, Roebber, & Bosart, 1997).Characteristically, we came to the topic of fraction-ated expertise with different examples in mind. GK focuseson the experts who perform a constant task (e.g., puttingout \ufb01res; establishing a diagnosis) but encounter unfamiliarsituations. The ability to recognize that a situation is anom-alous and poses a novel challenge is one of the manifesta-tions of authentic expertise. Descriptions of diagnosticthinking in medicine emphasize the intuitive ability of522 September 2009\u25cfAmerican Psychologistsome physicians to realize that the characteristics of a casedo not \ufb01t into any familiar category and call for a deliberatesearch for the true diagnosis (Gawande, 2002; Groopman,2007).DK is particularly interested in cases in which profes-sionals who know how to use their knowledge for somepurposes attempt to use the same knowledge for otherpurposes. He views the fractionation of expertise as oneelement in the explanation of the illusion of validity: theovercon\ufb01dence that professionals sometimes experience indealing with problems in which they have little or no skill.Finance professionals, psychotherapists, and intelligenceanalysts may know a great deal about a particular company,patient, or international con\ufb02ict, and they may have re-ceived ample feedback supporting their con\ufb01dence in theperformance of some tasks\u2014typically those that deal withthe short term\u2014but the feedback they receive from theirfailures in long-term judgments is delayed, sparse, andambiguous. The experience of the professionals that DKhas thought about is therefore conducive to overcon\ufb01dence.These professionals may have strong subjective con-\ufb01dence in their judgments, but we do not believe thatsubjective con\ufb01dence reliably indicates whether intuitivejudgments or decisions are valid. When experts recognizeanomalies, using judgments of typicality and familiarity,they are detecting violations of patterns in theexternalsituation. In contrast, people do not have a strong ability todistinguish correct intuitions from faulty ones. People, evenexperts, do not appear to be skilled in detecting patterns intheinternalsituation in order to identify the basis for theirjudgments. Therefore, reliance on subjective con\ufb01dencemay contribute to overcon\ufb01dence.The experts that GK has studied seem less susceptibleto overcon\ufb01dence, perhaps in part because of the directpersonal risks it poses. Weather forecasters, engineers, andlogistics specialists typically resist requests to make judg-ments about matters that fall outside their area of compe-tence. People in professions marked by standard methods,clear feedback, and direct consequences for error appear toappreciate the boundaries of their expertise. These expertsknow more knowledgeable experts exist. Weather forecast-ers know there are people in another location who betterunderstand the local dynamics. Structural engineers knowthat chemical engineers, or even structural engineers work-ing with different types of models or materials, are the trueexperts who should be consulted.As in the other topics that we have considered, we \ufb01ndno reason to disagree about either fractionation of expertiseor overcon\ufb01dence. As usual, different rules apply to dif-ferent tasks.Augmenting Professional Judgment:The Use of AlgorithmsThe attitude toward the Meehl paradigm, in which intui-tions and professional judgments are set in competition, isa sore point in conversations between adherents of NDMand HB. The idea of algorithms that outdo human judges isa source of pride and joy for members of the HB tribe, butalgorithms are usually distrusted by the NDM community.There is compelling evidence that under certain con-ditions mechanical and analytical judgments outperformhuman judgment. Grove, Zald, Lebow, Snitz, and Nelson(2000) reported a meta-analysis of 136 studies that com-pared the accuracy of clinical and mechanical judgments,most within the domains of clinical psychology and med-icine. Their review excluded studies involving nonhumanoutcomes such as horse races and weather. The preponder-ance of data favored the algorithms (i.e., the \u201cmechanical\u201djudgments), which were superior in about half the studies(n/H1100563). The other half of the studies showed no differ-ence (n/H1100565), and only a few studies showed betterperformance by the clinical judgments (n/H110058). For exam-ple, the tasks for which there was at least a 17-pointdifference in effect size favoring mechanical over clinicaljudgments included the following: college academic per-formance, presence of throat infections, diagnosis of gas-trointestinal disorders, length of psychiatric hospitalization,job turnover, suicide attempts, juvenile delinquency, ma-lingering, and occupational choice.Findings in which the performance of human judges isinferior to that of simple algorithms are often cited asevidence of cognitive ineptitude, but this conclusion isunwarranted. The correct conclusion is that people performsigni\ufb01cantly more poorly than algorithmsin low-validityenvironments. The tasks reviewed by Grove et al. (2000)generally involved noisy and/or highly complex situations.The forecasts made by the algorithms were often wrong,albeit less often than the clinical predictions. The studies inthe Meehl paradigm have not produced \u201csmoking gun\u201ddemonstrations in which clinicians miss highly valid cuesthat the algorithm detects and uses. Indeed, such an out-come would be unlikely, because human learning is nor-mally quite ef\ufb01cient. Where simple and valid cues exist,humans will \ufb01nd them if they are given suf\ufb01cient experi-ence and enough rapid feedback to do so\u2014except in theenvironments that Hogarth (2001) labeled \u201cwicked,\u201d inwhich the feedback is misleading. A statistical approachhas two crucial advantages over human judgment whenavailable cues are weak and uncertain: Statistical analysisis more likely to identify weakly valid cues, and a predic-tion algorithm will maintain above-chance accuracy byusing such cues consistently. The meta-analysis performedby Karelaia and Hogarth (2008) showed that consistencyaccounted for much of the advantage of algorithms overhumans.The evaluation and approval of personal loans by loanof\ufb01cers is an example of a situation in which algorithmsshould be used to replace human judgment. Identifying therelatively small number of defaulting loans is a low-valid-ity task because of the low base rate of the critical outcome.Algorithms have largely replaced human judges in thistask, using as inputs objective demographic and personaldata rather than subjective impression of reliability. Theresult is an unequivocal improvement: We have fairer loanjudgments (i.e., judgments that are not improperly in\ufb02u-enced by gender or race), faster decisions, and reducedexpenses.523September 2009\u25cfAmerican PsychologistOur analysis suggests that algorithms signi\ufb01cantlyoutperform humans under two quite different conditions:(a) when validity is so low that human dif\ufb01culties indetecting weak regularities and in maintaining consistencyof judgment are critical and (b) when validity is very high,in highly predictable environments, where ceiling effectsare encountered and occasional lapses of attention cancause humans to fail. Automatic transportation systems inairports are an example in that class.NDM proponents correctly emphasize that the condi-tions necessary for the construction and use of an algorithmare stringent. These conditions include (a) con\ufb01dence in theadequacy of the list of variables that will be used, (b) areliable and measurable criterion, (c) a body of similarcases, (d) a cost/bene\ufb01t ratio that warrants the investmentin the algorithmic approach, and (e) a low likelihood thatchanging conditions will render the algorithm obsolete. Wealso agree that algorithms that substitute for human judg-ment must remain under human supervision, to providecontinuous monitoring of their performance and of relevantchanges in the environment. Maintaining adequate super-vision of algorithms can be dif\ufb01cult, because there is evi-dence that human operators become more passive and lessvigilant when algorithms are in charge\u2014a phenomenonthat has been labeled \u201cautomation bias\u201d (Skitka, Mosier &Burdick, 1999, 2000).We agree that the introduction of algorithms and otherformal decision aids in organizations will often encounteropposition and unexpected problems of implementation.Few people enjoy being replaced by mechanical devices orby mathematical algorithms, and many devices and algo-rithms function less well in the real world than on theplanning board (Yates, Veinott, & Patalano, 2003). Evendecision aids and procedures that leave the authority of thedecision maker intact\u2014decision analysis is a salient exam-ple\u2014are often resisted, for both good and bad reasons.Naturally, we have somewhat different attitudes towardthese problems of implementation, with DK usually view-ing them as obstacles to be overcome and GK seeing themas reasons to be skeptical about the value of formal methods.Despite our different attitudes toward formal methods,we agree on the potential of semi-formal strategies. Anexample is the premortem method (Klein, 2007) for reduc-ing overcon\ufb01dence and improving decisions. Project teamsusing this method start by describing their plan. Next theyimagine that their plan has failed and the project has beena disaster. Their task is to write down, in two minutes, allthe reasons why the project failed. The facilitator goesaround the table, getting reasons from each of the teammembers, starting with the leader. The rationale for themethod is the concept of prospective hindsight (Mitchell,Russo, & Pennington, 1989)\u2014that people can generatemore criticisms when they are told that an outcome iscertain. It also offers a solution to one of the major prob-lems of decision making within organizations: the gradualsuppression of dissenting opinions, doubts, and objections,which is typically observed as an organization commitsitself to a major plan. The premortem method is consistentwith the HB concern for overcon\ufb01dence while drawing onand respecting the expertise of decision makers, a hallmarkof the NDM approach. We expect that there are additionalmethods that can synthesize the strengths of the two traditions.ConclusionsIn an effort that spanned several years, we attempted toanswer one basic question: Under what conditions are theintuitions of professionals worthy of trust? We do not claimthat the conclusions we reached are surprising (many wereanticipated by Shanteau, 1992, Hogarth, 2001, and Myers,2002, among others), but we believe that they add up to acoherent view of expert intuition, which is more than weexpected to achieve when we began.\u25cfOur starting point is that intuitive judgments canarise from genuine skill\u2014the focus of the NDMapproach\u2014but that they can also arise from inap-propriate application of the heuristic processes onwhich students of the HB tradition have focused.\u25cfSkilled judges are often unaware of the cues thatguide them, and individuals whose intuitions are notskilled are even less likely to know where theirjudgments come from.\u25cfTrue experts, it is said, know when they don\u2019t know.However, nonexperts (whether or not they thinkthey are) certainly do not know when they don\u2019tknow. Subjective con\ufb01dence is therefore an unreli-able indication of the validity of intuitive judgmentsand decisions.\u25cfThe determination of whether intuitive judgmentscan be trusted requires an examination of the envi-ronment in which the judgment is made and of theopportunity that the judge has had to learn theregularities of that environment.\u25cfWe describe task environments as \u201chigh-validity\u201d ifthere are stable relationships between objectively iden-ti\ufb01able cues and subsequent events or between cuesand the outcomes of possible actions. Medicine and\ufb01re\ufb01ghting are practiced in environments of fairlyhigh validity. In contrast, outcomes are effectivelyunpredictable in zero-validity environments. To agood approximation, predictions of the future value ofindividual stocks and long-term forecasts of politicalevents are made in a zero-validity environment.\u25cfValidity and uncertainty are not incompatible. Someenvironments are both highly valid and substan-tially uncertain. Poker and warfare are examples.The best moves in such situations reliably increasethe potential for success.\u25cfAn environment of high validity is a necessarycondition for the development of skilled intuitions.Other necessary conditions include adequate oppor-tunities for learning the environment (prolongedpractice and feedback that is both rapid and un-equivocal). If an environment provides valid cuesand good feedback, skill and expert intuition willeventually develop in individuals of suf\ufb01cient talent.\u25cfAlthough true skill cannot develop in irregular orunpredictable environments, individuals will some-524 September 2009\u25cfAmerican Psychologisttimes make judgments and decisions that are suc-cessful by chance. These \u201clucky\u201d individuals will besusceptible to an illusion of skill and to overcon\ufb01-dence (Arkes, 2001). The \ufb01nancial industry is a richsource of examples.\u25cfThe situation that we have labeled fractionation ofskill is another source of overcon\ufb01dence. Profes-sionals who have expertise in some tasks are some-times called upon to make judgments in areas inwhich they have no real skill. (For example, \ufb01nan-cial analysts may be skilled at evaluating the likelycommercial success of a \ufb01rm, but this skill does notextend to the judgment of whether the stock of that\ufb01rm is underpriced.) It is dif\ufb01cult both for theprofessionals and for those who observe them todetermine the boundaries of their true expertise.\u25cfWe agree that the weak regularities available inlow-validity situations can sometimes support thedevelopment of algorithms that do better thanchance. These algorithms only achieve limited ac-curacy, but they outperform humans because oftheir advantage of consistency. However, the intro-duction of algorithms to replace human judgment islikely to evoke substantial resistance and sometimeshas undesirable side effects.Another conclusion that we both accept is that theapproaches of our respective communities have built-inlimitations. For historical and methodological reasons, HBresearchers generally \ufb01nd errors more interesting and in-structive than correct performance; but a psychology ofjudgment and decision making that ignores intuitive skill isseriously blinkered. Because their intellectual attitudes de-veloped in reaction to the HB tradition, members of theNDM community have an aversion to the wordbiasand tothe corresponding concept; but a psychology of profes-sional judgment that neglects predictable errors cannot beadequate. Although we agree with both of these conclu-sions, we have yet to move much beyond recognition of theproblem. DK is still fascinated by persistent errors, and GKstill recoils when biases are mentioned. We hope, however,that our effort may help others do more than we have beenable to do in bringing the insights of both communities tobear on their common subject.REFERENCESArkes, H. R. (2001). Overcon\ufb01dence in judgmental forecasting. In J. S.Armstrong (Ed.),Principles of forecasting: A handbook for researchersand practitioners(pp. 495\u2013516). Boston: Kluwer Academic.Bazerman, M. H. (2005).Judgment in managerial decision making(6thed.). Hoboken, NJ: Wiley.Beach, L. R. (1990).Image theory: Decision making in personal andorganizational contexts.Chichester, England: Wiley.Brunswik, E. (1957). Scope and aspects of the cognitive problem. In H.Gruber, K. R. Hammond, & R. Jessor (Eds.),Contemporary ap-proaches to cognition(pp. 5\u201331). Cambridge, MA: Harvard UniversityPress.Cannon-Bowers, J. A., & Salas, E. (Eds.). (1998).Making decisions understress: Implications for individual and team training.Washington, DC:American Psychological Association.Chase, W. G., & Simon, H. A. (1973). The mind\u2019s eye in chess. In W. G.Chase (Ed.),Visual information processing(pp. 215\u2013281). New York:Academic Press.Collyer, S. C., & Malecki, G. S. (1998). Tactical decision making understress: History and overview. In J. A. Cannon-Bowers & E. Salas(Eds.),Making decisions under stress: Implications for individual andteam training(pp. 3\u201315). Washington, DC: American PsychologicalAssociation.Crandall, B., & Gamblian, V. (1991).Guide to early sepsis assessment inthe NICU[Instruction manual prepared for the Ohio Department ofDevelopment under the Ohio Small Business Innovation ResearchBridge Grant program]. Fairborn, OH: Klein Associates.Crandall, B., & Getchell-Reiter, K. (1993). Critical decision method: Atechnique for eliciting concrete assessment indicators from the \u201cintu-ition\u201d of NICU nurses.Advances in Nursing Sciences, 16(1), 42\u201351.Crandall, B., Klein, G., & Hoffman, R. R. (2006).Working minds: Apractitioner\u2019s guide to cognitive task analysis.Cambridge, MA: MITPress.Croskerry, P., & Norman, G. (2008). Overcon\ufb01dence in clinical decisionmaking.The American Journal of Medicine, 121,S24\u2013S29.deGroot, A. D. (1978).Thought and choice in chess.The Hague: Mouton.(Original work published 1946)Einhorn, H. J., & Hogarth, R. M. (1978). Con\ufb01dence in judgment:Persistence of the illusion of validity.Psychological Review, 85,395\u2013416.Ericsson, K. A. (2006). The in\ufb02uence of experience and deliberate prac-tice on the development of superior expert performance. In K. A.Ericsson, N. Charness, R. R. Hoffman, & P. J. Feltovich (Eds.),TheCambridge handbook of expertise and expert performance(pp. 39\u201368).New York: Cambridge University Press.Ericsson, K. A., Charness, N., Hoffman, R. R., & Feltovich, P. J. (Eds.).(2006).The Cambridge handbook of expertise and expert performance.New York: Cambridge University Press.Evans, J. St. B. T. (2007).Hypothetical thinking: Dual processes inreasoning and judgment.Hove, East Sussex, England: PsychologyPress.Evans, J. St. B. T., & Frankish, K. (Eds.). (2009).In two minds: Dualprocesses and beyond.New York: Oxford University Press.Fogarty, W. M. (1988).Formal investigation into the circumstancessurrounding the downing of a commercial airliner by the U. S. S.Vincennes (CG 49) on 3 July 1988[Unclassi\ufb01ed Letter Ser. 1320 of 28July 1988, to Commander in Chief, U.S. Central Command]. Washing-ton, DC: U.S. Department of the Navy.Frederick, S. (2005). Cognitive re\ufb02ection and decision making.Journal ofEconomic Perspectives, 19(4), 25\u201342.Gawande, A. (2002).Complications: A surgeon\u2019s notes on an imperfectscience.London: Pro\ufb01le Books.Gilovich, T., Grif\ufb01n, D., & Kahneman, D. (Eds.). (2002).Heuristics andbiases: The psychology of intuitive judgment.New York: CambridgeUniversity Press.Goldberg, L. R. (1970). Man versus model of man: A rationale, plus someevidence, for a method of improving on clinical inferences.Psycholog-ical Bulletin, 73,422\u2013432.Goldstein, D. G., & Gigerenzer, G. (1999). The recognition heuristic:How ignorance makes us smart. In G. Gigerenzer, P. M. Todd, &A. B. C. Research Group (Eds.),Simple heuristics that make us smart(pp. 37\u201358). New York: Oxford University Press.Grif\ufb01n, D. W., & Tversky, A. (1992). The weighing of evidence and thedeterminants of con\ufb01dence.Cognitive Psychology, 24,411\u2013435.Groopman, J. (2007).How doctors think.New York: Houghton Mif\ufb02in.Grove, W. M., Zald, D. H., Lebow, B. S., Snitz, B. E., & Nelson, C.(2000). Clinical versus mechanical prediction: A meta-analysis.Psy-chological Assessment, 12,19\u201330.Guthrie, C., Rachlinski, J. J., & Wistrich, A. J. (2007). Blinking on thebench: How judges decide cases.Cornell Law Review, 93,1\u201343.Hammond, K. R., Hamm, R. M., Grassia, J., & Pearson, T. (1987). Directcomparison of the ef\ufb01cacy of intuitive and analytical cognition inexpert judgment.IEEE Transactions on Systems, Man, and Cybernet-ics, SMC-17(5), 753\u2013770.Hertwig, R., Hoffrage, U., & Martingnon, L. (1999). Quick estimation:Letting the environment do the work. In G. Gigerenzer, P. M. Todd, &A. B. C. Research Group (Eds.),Simple heuristics that make us smart(pp. 37\u201358). New York: Oxford University Press.525September 2009\u25cfAmerican PsychologistHogarth, R. M. (2001).Educating intuition.Chicago: University of Chi-cago Press.Jacowitz, K. E., & Kahneman, D. (1995). Measures of anchoring inestimation tasks.Personality and Social Psychology Bulletin, 21,1161\u20131166.Johnson, J. G., & Raab, M. (2003). Take the \ufb01rst: Option generation andresulting choices.Organizational Behavior and Human Decision Pro-cesses, 91(2), 215\u2013229.Kahneman, D. (2003). Autobiography. In T. Frangsmyr (Ed.),Les PrixNobel 2002[Nobel Prizes 2002]. Stockholm, Sweden: Almqvist &Wiksell International.Kahneman, D., & Frederick, S. (2002). Representativeness revisited:Attribute substitution in intuitive judgment. In T. Gilovich, D. Grif\ufb01n,& D. Kahneman (Eds.),Heuristics and biases: The psychology ofintuitive judgment(pp. 49\u201381). New York: Cambridge UniversityPress.Kahneman, D., & Renshon, J. (2007). Why hawks win.Foreign Policy,158,34\u201338.Kahneman, D., & Tversky, A. (1973). On the psychology of prediction.Psychological Review, 80,237\u2013251.Karelaia, N., & Hogarth, R. M. (2008). Determinants of linear judgment:A meta-analysis of lens model studies.Psychological Bulletin, 134,404\u2013426.Klein, G. A. (1993). A recognition-primed decision (RPD) model of rapiddecision making. In G. A. Klein, J. Orasanu, R. Calderwood, & C. E.Zsambok (Eds.),Decision making in action: Models and methods(pp.138\u2013147). Norwood, NJ: Ablex.Klein, G. (1998).Sources of power: How people make decisions.Cam-bridge, MA: MIT Press.Klein, G. (2007, September). Performing a project premortem.HarvardBusiness Review,pp. 18\u201319.Klein, G. A., Calderwood, R., & Clinton-Cirocco, A. (1986). Rapiddecision making on the \ufb01reground. InProceedings of the HumanFactors and Ergonomics Society 30th Annual Meeting(Vol. 1, pp.576\u2013580). Norwood, NJ: Ablex.Klein, G. A., Orasanu, J., Calderwood, R., & Zsambok, C. E. (1993).Decision making in action: Models and methods.Norwood, NJ: Ablex.Klein, G., Wolf, S., Militello, L., & Zsambok, C. (1995). Characteristicsof skilled option generation in chess.Organizational Behavior andHuman Decision Processes, 62,63\u201369.Lewis, M. (2003).Moneyball: The art of winning an unfair game.NewYork: Norton.Lipshitz, R. (1993). Converging themes in the study of decision making inrealistic settings. In G. A. Klein, J. Orasanu, R. Calderwood, & C. E.Zsambok (Eds.),Decision making in action: Models and methods(pp.103\u2013137). Norwood, NJ: Ablex.Mednick, S. A. (1962). The associative basis of the creative process.Psychological Review, 69,220\u2013232.Meehl, P. E. (1954).Clinical vs. statistical prediction: A theoreticalanalysis and a review of the evidence.Minneapolis: University ofMinnesota Press.Meehl, P. E. (1973). Why I do not attend case conferences. In P. E. Meehl(Ed.),Psychodiagnosis: Selected papers(pp. 225\u2013302). Minneapolis:University of Minnesota Press.Mitchell, D., Russo, J., & Pennington, N. (1989). Back to the future:Temporal perspective in the explanation of events.Journal of Behav-ioral Decision Making, 2,25\u201338.Montgomery, H. (1993). The search for a dominance structure in decisionmaking: Examining the evidence. In G. A. Klein, J. Orasanu, R.Calderwood, & C. E. Zsambok (Eds.),Decision making in action:Models and methods(pp. 182\u2013187). Norwood, NJ: Ablex.Mussweiler, T., & Strack, F. (2000). The use of category and exemplarknowledge in the solution of anchoring tasks.Journal of Personalityand Social Psychology, 78,1038\u20131052.Myers, D. G. (2002).Intuition: Its powers and perils.New Haven, CT:Yale University Press.Nisbett, R. E., & Wilson, T. D. (1977). Telling more than we can know:Verbal reports on mental processes.Psychological Review, 84,231\u2013259.Orasanu, J., & Connolly, T. (1993). The reinvention of decision making.In G. A. Klein, J. Orasanu, R. Calderwood, & C. E. Zsambok (Eds.),Decision making in action: Models and methods(pp. 3\u201320). Norwood,NJ: Ablex.Rasmussen, J. (1986).Information processing and human\u2013machine inter-action: An approach to cognitive engineering.Amsterdam: North-Holland.Rosenzweig, P. (2007).The halo effect . . . and the eight other businessdelusions that deceive managers.New York: Free Press.Schraagen, J. M. C., Chipman, S. F., & Shalin, V. J. (Eds.). (2000).Cognitive task analysis.Mahwah, NJ: Erlbaum.Shanteau, J. (1992). Competence in experts: The role of task character-istics.Organizational Behavior and Human Decision Processes, 53,252\u2013262.Simon, H. A. (1992). What is an explanation of behavior?PsychologicalScience, 3,150\u2013161.Skitka, L. J., Mosier, K., & Burdick, M. D. (1999). Does automation biasdecision-making?International Journal of Human\u2013Computer Studies,51,991\u20131006.Skitka, L. J., Mosier, K., & Burdick, M. D. (2000). Accountability andautomation bias.International Journal of Human\u2013Computer Studies,52,701\u2013717.Slovic, P. (Ed.). (2000).The perception of risk.London: Earthscan.Smith, P. J., Gif\ufb01n, W. C., Rockwell, T. H., & Thomas, M. (1986).Modeling fault diagnosis as the activation and use of a frame system.Human Factors, 28,703\u2013716.Stewart, T. R., Roebber, P. J., & Bosart, L. F. (1997). The importance ofthe task in analyzing expert judgment.Organizational Behavior andHuman Decision Processes, 69,205\u2013219.Sunstein, C. R. (Ed.). (2000).Behavioral law and economics.New York:Cambridge University Press.Tetlock, P. E. (2005).Expert political judgment: How good is it? How canwe know?Princeton, NJ: Princeton University Press.Tversky, A., & Kahneman, D. (1971). Belief in the law of small numbers.Psychological Bulletin, 76,105\u2013110.Tversky, A., & Kahneman, D. (1974). Judgment under uncertainty: Heu-ristics and biases.Science, 185,1124\u20131131.Woods, D. D., O\u2019Brien, J., & Hanes, L. F. (1987). Human factorschallenges in process control: The case of nuclear power plants. In G.Salvendy (Ed.),Handbook of human factors/ergonomics(pp. 1724\u20131770). New York: Wiley.Yates, J. F., Veinott, E. S., & Patalano, A. L. (2003). Hard decisions, baddecisions: On decision quality and decision aiding. In S. L. Schneider& J. C. Shanteau (Eds.),Emerging perspectives on judgment anddecision research(pp. 13\u201363). New York: Cambridge University Press.\n526 September 2009\u25cfAmerican Psychologist\nView publication stats"}], "max_tokens": 1000}}
{"custom_id": "prompt_2_Test_pdf.pdf", "method": "POST", "url": "/v1/chat/completions", "body": {"model": "gpt-4o", "messages": [{"role": "system", "content": "You are tasked with extracting key data points and verbatim quotations from research papers focused on development programs and behavior change. Your goal is to distill essential information, capture direct quotes that provide valuable insights, and present these data in an organized manner for easy reference by a behavior change research team.\n\nExtraction Structure: The extracted content should be divided into the following sections:\n1. Basic Information\n   - Title: Provide the title of the paper.\n   - Authors and Publication Year: Summarize the author(s) and the year of publication.\n   - Program Focus: Briefly describe the overall context and focus of the development program discussed in the paper.\n   - Geographic and Demographic Scope: Note the country/region and target population of the program.\n\n2. Key Data Points\n   - Quantitative Data: Extract key statistics, figures, and percentages related to the behavior change program (e.g., % increase in adoption rates, reduction in harmful behaviors).\n   - Qualitative Data: Include any notable qualitative insights that are summarized in the paper, such as descriptions of participant behaviors or community responses.\n   - Stakeholder Information: Extract details about the stakeholders involved (e.g., community members, program implementers, government bodies).\n\n3. Behavioral Barriers and Solutions\n   - Barriers: Extract verbatim descriptions of behavioral barriers identified in the paper (e.g., cultural norms, lack of awareness, economic challenges).\n   - Interventions: Extract direct quotes or summarized points about the interventions used to address these barriers, including details on behavioral principles applied.\n\n4. Quotations\n   - Key Quotes: Extract direct quotations from participants, stakeholders, or authors that illustrate the challenges, interventions, and outcomes of the program.\n   - Insights from Authors: Include any verbatim quotes from the authors that provide unique insights or key takeaways relevant to behavior change.\n\nWhere relevant, use bullet points for clarity and easy organization of the extracted information.\n\nExample 1:\n   - Title: \"Influencing Water Conservation Behaviors in Rural India: A Case Study\"\n   - Authors and Publication Year: R. Sharma and S. Gupta, 2021\n   - Program Focus: The paper examines a community-driven initiative aimed at encouraging water conservation behaviors among rural households in Rajasthan, India.\n   - Geographic and Demographic Scope: Rajasthan, India; rural households with a focus on farmers.\n   - Key Data Points:\n     - Reduction in Water Usage: \"Households that participated in the program reduced water usage by 25%.\"\n     - Community Engagement: Over 80% of households attended at least one community workshop.\n   - Behavioral Barriers and Solutions:\n     - Barrier: \"Deep-rooted cultural norms contributed to the perception that water was an abundant resource.\"\n     - Solution: \"Community workshops led by local leaders helped shift perceptions about water scarcity.\"\n   - Quotations:\n     - Participant Quote: \"We never realized how much water we were wasting until we started keeping track.\"\n     - Author Insight: \"The success of the program relied heavily on the involvement of respected community figures.\"\n\nExample 2:\n   - Title: \"Behavioral Nudges to Promote Handwashing in Schools: Insights from Bangladesh\"\n   - Authors and Publication Year: A. Rahman et al., 2019\n   - Program Focus: This study explores interventions aimed at increasing handwashing with soap among students in primary schools in Bangladesh.\n   - Geographic and Demographic Scope: Rural and urban schools in Bangladesh; primary school students aged 6-12.\n   - Key Data Points:\n     - Handwashing Increase: \"Handwashing rates increased by 40% after the introduction of visual cues and peer leaders.\"\n     - Illness Reduction: \"The incidence of diarrhea dropped by 15% over a six-month period.\"\n   - Behavioral Barriers and Solutions:\n     - Barrier: \"Children often felt that diseases were not a significant threat.\"\n     - Solution: \"The use of peer leaders helped normalize handwashing as a social behavior.\"\n   - Quotations:\n     - Student Quote: \"I started washing my hands because my friends were doing it too.\"\n     - Author Insight: \"Peer-led interventions proved particularly effective in this context due to the strong influence of social proof among children.\"\n"}, {"role": "user", "content": "See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/26798603\nConditions for Intuitive Expertise A Failu re to Disagree\nArticle \u00a0\u00a0 in\u00a0\u00a0Americ an P sychologist  \u00b7 Sept ember 2009\nDOI: 10.1037/ a0016755 \u00a0\u00b7\u00a0Sour ce: PubMed\nCITATIONS\n2,021READS\n19,968\n2 author s, including:\nGary Klein\nShado wBo x LL C & Macr oCognition LL C\n259 PUBLICA TIONS \u00a0\u00a0\u00a022,811  CITATIONS \u00a0\u00a0\u00a0\nSEE PROFILE\nAll c ontent f ollo wing this p age was uplo aded b y Gary Klein  on 25 No vember 2015.\nThe user has r equest ed enhanc ement of the do wnlo aded file.Conditions for Intuitive ExpertiseA Failure to DisagreeDaniel KahnemanPrinceton UniversityGary KleinApplied Research AssociatesThis article reports on an effort to explore the differencesbetween two approaches to intuition and expertise that areoften viewed as con\ufb02icting: heuristics and biases (HB) andnaturalistic decision making (NDM). Starting from theobvious fact that professional intuition is sometimes mar-velous and sometimes \ufb02awed, the authors attempt to mapthe boundary conditions that separate true intuitive skillfrom overcon\ufb01dent and biased impressions. They concludethat evaluating the likely quality of an intuitive judgmentrequires an assessment of the predictability of the environ-ment in which the judgment is made and of the individual\u2019sopportunity to learn the regularities of that environment.Subjective experience is not a reliable indicator of judg-ment accuracy.Keywords:intuition, expertise, overcon\ufb01dence, heuristics,judgmentIn this article we report on an effort to compare ourviews on the issues of intuition and expertise and todiscuss the evidence for our respective positions. Whenwe launched this project, we expected to disagree on manyissues, and with good reason: One of us (GK) has spentmuch of his career thinking about ways to promote relianceon expert intuition in executive decision making and iden-ti\ufb01es himself as a member of the intellectual community ofscholars and practitioners who study naturalistic decisionmaking (NDM). The other (DK) has spent much of hiscareer running experiments in which intuitive judgmentwas commonly found to be \ufb02awed; he is identi\ufb01ed with the\u201cheuristics and biases\u201d (HB) approach to the \ufb01eld.A surprise awaited us when we got together to con-sider our joint \ufb01eld of interest. We found ourselves agree-ing most of the time. Where we initially disagreed, we wereusually able to converge upon a common position. Ourshared beliefs are much more speci\ufb01c than the common-place that expert intuition is sometimes remarkably accu-rate and sometimes off the mark. We accept the common-place, of course, but we also have similar opinions aboutmore speci\ufb01c questions: What are the activities in whichskilled intuitive judgment develops with experience? Whatare the activities in which experience is more likely toproduce overcon\ufb01dence than genuine skill? Because welargely agree about the answers to these questions we alsofavor generally similar recommendations to organizationsseeking to improve the quality of judgments and decisions.In spite of all this agreement, however, we \ufb01nd that we arestill separated in many ways: by divergent attitudes, pref-erences about facts, and feelings about \ufb01ghting words suchas \u201cbias.\u201d If we are to understand the differences betweenour respective communities, such emotions must be takeninto account.We begin with a brief review of the origins andprecursors of the NDM and HB approaches, followed by adiscussion of the most prominent points of contrast be-tween them (NDM: Klein, Orasanu, Calderwood, & Zsam-bok, 1993; HB: Gilovich, Grif\ufb01n, & Kahneman, 2002;Tversky & Kahneman, 1974). Next we present some claimsabout the conditions under which skilled intuitions de-velop, followed by several suggestions for ways to improvethe quality of judgments and choices.Two PerspectivesOrigins of the Naturalistic DecisionMaking ApproachThe NDM approach, which focuses on the successesof expert intuition, grew out of early research on masterchess players conducted by deGroot (1946/1978) and laterby Chase and Simon (1973). DeGroot showed that chessgrand masters were generally able to identify the mostpromising moves rapidly, while mediocre chess playersoften did not even consider the best moves. The chessgrand masters mainly differed from weaker players in theirunusual ability to appreciate the dynamics of complexpositions and quickly judge a line of play as promising orfruitless. Chase and Simon (1973) described the perfor-mance of chess experts as a form of perceptual skill inwhich complex patterns are recognized. They estimatedthat chess masters acquire a repertoire of 50,000 to 100,000immediately recognizable patterns, and that this repertoireenables them to identify a good move without having tocalculate all possible contingencies. Strong players need adecade of serious play to assemble this large collection ofbasic patterns, but of course they achieve impressive levelsDaniel Kahneman, Woodrow Wilson School of Public and InternationalAffairs, Princeton University; Gary Klein, Applied Research Associates,Fairborn, Ohio.We thank Craig Fox, Robin Hogarth, and James Shanteau for theirhelpful comments on earlier versions of this article.Correspondence concerning this article should be addressed to DanielKahneman, Woodrow Wilson School of Public and International Affairs,Princeton University, Princeton, NJ 08544-0001. E-mail: kahneman@princeton.edu515September 2009\u25cfAmerican Psychologist\u00a9 2009 American Psychological Association 0003-066X/09/$12.00Vol. 64, No. 6, 515\u2013526 DOI: 10.1037/a0016755of skill even earlier. On the basis of this work, Simonde\ufb01ned intuition as the recognition of patterns stored inmemory.The early work that led to the approach that is nowcalled NDM was an attempt to describe and analyze thedecision making of commanders of \ufb01re\ufb01ghting companies.Fireground commanders are required to make decisionsunder conditions of uncertainty and time pressure thatpreclude any orderly effort to generate and evaluate sets ofoptions. Klein, Calderwood, and Clinton-Cirocco (1986)investigated how the commanders could make good deci-sions without comparing options. The initial hypothesiswas that commanders would restrict their analysis to onlya pair of options, but that hypothesis proved to be incorrect.In fact, the commanders usually generated only a singleoption, and that was all they needed. They could draw onthe repertoire of patterns that they had compiled duringmore than a decade of both real and virtual experience toidentify a plausible option, which they considered \ufb01rst.They evaluated this option by mentally simulating it to seeif it would work in the situation they were facing\u2014aprocess that deGroot (1946/1978) had described as progres-sive deepening. If the course of action they were consid-ering seemed appropriate, they would implement it. If ithad shortcomings, they would modify it. If they could noteasily modify it, they would turn to the next most plausibleoption and run through the same procedure until an accept-able course of action was found. This recognition-primeddecision (RPD) strategy was effective because it took ad-vantage of the commanders\u2019 tacit knowledge (Klein et al.,1986). The \ufb01reground commanders were able to draw ontheir repertoires to anticipate how \ufb02ames were likely tospread through a building, to notice signs that a house waslikely to collapse, to judge when to call for additionalsupport, and to make many other critical decisions. TheRPD model is consistent with the work of deGroot (1946/1978) and Simon (1992) and has been replicated in multi-ple domains, including system design, military commandand control, and management of offshore oil installations(see Klein, 1998, for a review). In each of these domains,the RPD model offers a generally encouraging picture ofexpert performance. It would be a caricature of the NDMapproach, however, to describe it as being solely dedicatedto praising expertise. NDM researchers have also tried todocument and analyze failures in the performance of ex-perts (Cannon-Bowers & Salas, 1998; Klein, 1998; Woods,O\u2019Brien, & Hanes, 1987). In fact, the NDM movement wascrystallized by an event that resulted from a catastrophicfailure in expert decision making.In 1988, an international tragedy occurred after theUSSVincennesaccidentally shot down an Iranian Airbus(Fogarty, 1988). The USSVincenneswas an Aegis cruiser,one of the most technologically advanced systems in theNavy inventory, but the technology was not suf\ufb01cient tostave off the disaster. The incident has been the subject ofdetailed investigation by NDM researchers (Collyer &Malecki, 1998; Klein, 1998). As a result of the disastrouserror and subsequent political fallout, the U.S. Navy de-cided to initiate a program of research on decision making,the Tactical Decision Making Under Stress (TADMUS)program (Cannon-Bowers & Salas, 1998).Thus it was that in 1989 a group of 30 researchers whostudied decision making in natural settings met for severaldays in an effort to \ufb01nd commonalities between the deci-sion-making processes of \ufb01re\ufb01ghters, nuclear power plantcontrollers, Navy of\ufb01cers, Army of\ufb01cers, highway engi-neers, and other populations. Several researchers from thejudgment and decision making tradition participated in thismeeting and in the preparation of a book describing theNDM perspective (Klein et al., 1993). Lipshitz (1993)identi\ufb01ed several decision-making models that were devel-oped to describe the strategies used in \ufb01eld settings, in-cluding the recognition-primed decision model (Klein,1993), the cognitive continuum model (Hammond, Hamm,Grassia, & Pearson, 1987), image theory (Beach, 1990), thesearch for dominance structures (Montgomery, 1993), andthe skills/rules/knowledge framework and decision ladder(Rasmussen, 1986). The NDM movement that emergedfrom this meeting focuses on \ufb01eld studies of subject-matterexperts who make decisions under complex conditions.These experts are expected to successfully attain vaguelyde\ufb01ned goals in the face of uncertainty, time pressure, highstakes, team and organizational constraints, shifting condi-tions, and action feedback loops that enable people tomanage disturbances while trying to diagnose them(Orasanu & Connolly, 1993).A central goal of NDM is to demystify intuition byidentifying the cues that experts use to make their judg-ments, even if those cues involve tacit knowledge and aredif\ufb01cult for the expert to articulate. In this way, NDMresearchers try to learn from expert professionals. ManyNDM researchers use cognitive task analysis (CTA) meth-ods to investigate the cues and strategies that skilled deci-\nDanielKahneman\n516 September 2009\u25cfAmerican Psychologistsion makers apply (Crandall, Klein, & Hoffman, 2006;Schraagen, Chipman, & Shalin, 2000). CTA methods aresemi-structured interview techniques that elicit the cuesand contextual considerations in\ufb02uencing judgments anddecisions. Researchers cannot expect decision makers toaccurately explain why they made decisions (Nisbett &Wilson, 1977); CTA methods provide a basis for makinginferences about the judgment and decision process. Forexample, Crandall and Getchell-Reiter (1993) studiednurses in a neonatal intensive care unit (NICU) who coulddetect infants developing life-threatening infections evenbefore blood tests came back positive. When asked, thenurses were at \ufb01rst unable to describe how they made theirjudgments. The researchers used CTA methods to probespeci\ufb01c incidents and identi\ufb01ed a range of cues and pat-terns, some of which had not yet appeared in the nursing ormedical literature. A few of these cues were opposite to theindicators of infection in adults. Crandall and Gamblian(1991) extended the NICU work. They con\ufb01rmed the \ufb01nd-ings with nurses from a different hospital and then createdan instructional program to help new NICU nurses learnhow to identify the early signs of sepsis in neonates. Thatprogram has been widely disseminated throughout thenursing community.Origins of the Heuristics and Biases ApproachIn sharp contrast to NDM, the HB approach favors askeptical attitude toward expertise and expert judgment.The origins of this attitude can be traced to a famousmonograph published by Paul Meehl in 1954. Meehl(1954) reviewed approximately 20 studies that comparedthe accuracy of forecasts made by human judges (mostlyclinical psychologists) and those predicted by simple sta-tistical models. The criteria in the studies that Meehl (1954)discussed were diverse, with outcome measures rangingfrom academic success to patient recidivism and propensityfor violence. Although the algorithms were based on asubset of the information available to the clinicians, statis-tical predictions were more accurate than human predic-tions in almost every case. Meehl (1954) believed that theinferiority of clinical judgment was due in part to system-atic errors, such as the consistent neglect of the base ratesof outcomes in discussion of individual cases. In a well-known article, he later explained his reluctance to attendclinical conferences by citing his annoyance with the cli-nicians\u2019 uncritical reliance on their intuition and their fail-ure to apply elementary statistical reasoning (Meehl, 1973).Inconsistency is a major weakness of informal judg-ment: When presented with the same case information onseparate occasions, human judges often reach differentconclusions. Goldberg (1970) reported a \u201cbootstrappingeffect,\u201d which provides the most dramatic illustration of theeffect of inconsistency on the validity of judgments. Gold-berg required a group of 29 clinicians to make diagnosticjudgments (psychotic vs. neurotic) in a set of cases, basedon personality test pro\ufb01les of 861 patients who had beenindependently assigned to one of these categories. He con-structed an individual model of the predictions of eachjudge\u2014using multiple regression to estimate the weightsthat the judge assigned to each of the 11 scales in theMinnesota Multiphasic Personality Inventory. Judges werethen required to make predictions for a new set of cases;Goldberg also used the individual statistical model of eachjudge to generate a prediction for these new cases. Thebootstrap models were almost always more accurate thanthe judges they modeled. The only plausible explanation ofthis remarkable result is that human judgments are noisy toan extent that substantially impairs their validity. In anextensive meta-analysis of judgment studies using the lensmodel, Karelaia and Hogarth (2008) reported strong sup-port for the generality of the bootstrap effect and for thecrucial importance of lack of consistency in explaining thiseffect.Kahneman read Meehl\u2019s book in 1955 while servingin the Psychological Research Unit of the Israel DefenseForces, and the book helped him make sense of his ownencounters with the dif\ufb01culties of clinical judgment. One ofKahneman\u2019s duties was to assess candidates for of\ufb01certraining, using \ufb01eld tests and other observations as well asa personal interview. Kahneman (2003) described the pow-erful sense of getting to know each candidate and theaccompanying conviction that he could foretell how wellthe candidate would do in further training and eventually incombat. The subjective conviction of understanding eachcase in isolation was not diminished by the statisticalfeedback from of\ufb01cer training school, which indicated thatthe validity of the assessments was negligible. Kahnemancoined the termillusion of validityfor the unjusti\ufb01ed senseof con\ufb01dence that often comes with clinical judgment. Hisearly experience with the fallibility of intuitive impressionscould hardly be more different from Klein\u2019s formativeencounter with the successful decision making of \ufb01re-ground commanders.\nGary Klein\n517September 2009\u25cfAmerican PsychologistThe \ufb01rst study in the HB tradition was conducted in1969 (Tversky & Kahneman, 1971). It described perfor-mance in a task that researchers often perform withoutrecourse to computation: choosing the number of cases fora psychological experiment. The participants in the studywere sophisticated methodologists and statisticians, includ-ing two authors of statistics textbooks. They answeredrealistic questions about the sample size they consideredappropriate in different situations. The conclusion of thestudy was that sophisticated scientists reached incorrectconclusions and made inferior choices when they followedtheir intuitions, failing to apply rules with which they werecertainly familiar. The article offered a strongly wordedrecommendation that researchers faced with the task ofchoosing a sample size should forsake intuition in favor ofcomputation. This initial study of professionals reinforcedTversky and Kahneman (1971) in their belief (originallybased on introspection) that faulty statistical intuitions sur-vive both formal training and actual experience. Manystudies in the intervening decades have con\ufb01rmed the per-sistence of a diverse set of intuitive errors in the judgmentsof some professionals.Contrasts Between the NaturalisticDecision Making and Heuristicsand Biases ApproachesThe intellectual traditions that we have traced to deGroot\u2019s(1946/1978) studies of chess masters (NDM) and to Meehl\u2019s(1954) research on clinicians (HB) are alive and well today.They are re\ufb02ected in the approaches of our respective intel-lectual communities. In this section we consider three impor-tant contrasts between the two approaches: the stance taken bythe NDM and HB researchers toward expert judgment, the useof \ufb01eld versus laboratory settings for decision-making re-search, and the application of different standards of perfor-mance, which leads to different conclusions about expertise.Stance Regarding Expertise andDecision AlgorithmsThere is no logical inconsistency between the observationsthat inspired the NDM and HB approaches to professionaljudgment: The intuitive judgments of some professionalsare impressively skilled, while the judgments of otherprofessionals are remarkably \ufb02awed. Although not contra-dictory, these core observations suggest con\ufb02icting gener-alizations about the utility of expert judgment. Members ofthe HB community are of course aware of the existence ofskill and expertise, but they tend to focus on \ufb02aws inhuman cognitive performance. Members of the NDM com-munity know that professionals often err, but they tend tostress the marvels of successful expert performance.The basic stance of HB researchers, as they considerexperts, is one of skepticism. They are trained to look foropportunities to compare expert performance with perfor-mance by formal models or rules and to expect that expertswill do poorly in such comparisons. They are predisposedto recommend the replacement of informal judgment byalgorithms whenever possible. Researchers in the NDMtradition are more likely to adopt an admiring stance to-ward experts. They are trained to explore the thinking ofexperts, hoping to identify critical features of the situationthat are obvious to experts but invisible to novices andjourneymen, and then to search for ways to pass on theexperts\u2019 secrets to others in the \ufb01eld. NDM researchers aredisposed to have little faith in formal approaches becausethey are generally skeptical about attempts to impose uni-versal structures and rules on judgments and choices thatwill be made in complex contexts.We found that the sharpest differences between thetwo of us were emotional rather than intellectual. AlthoughDK is thrilled by the remarkable intuitive skills of expertsthat GK and others have described, he also takes consid-erable pleasure in demonstrations of human folly and in thecomeuppance of overcon\ufb01dent pseudo-experts. For hispart, GK recognizes that formal procedures and algorithmssometimes outdo human judgment, but he enjoys hearingabout cases in which the bureaucratization of decisionmaking fails. Further, the nonoverlapping sets of col-leagues with whom we interact generally share our atti-tudes and reinforce our differences. Nevertheless, as thisarticle shows, we agree on most of the issues that matter.Field Versus LaboratoryThere is an obvious difference in the primary form of researchconducted by the respective research communities. The mem-bers of the HB community are mostly based in academicdepartments, and they tend to favor well-controlled experi-ments in the laboratory. The members of the NDM commu-nity are typically practitioners who operate in \u201creal-world\u201dorganizations. They have a natural sympathy for the ecolog-ical approach, \ufb01rst popularized in the late 1970s, which ques-tions the relevance of laboratory experiments to real-worldsituations. NDM researchers use methods such as cognitivetask analysis and \ufb01eld observation to investigate judgmentsand decision making under complex conditions that would bedif\ufb01cult to recreate in the laboratory.There is no logically necessary connection between thesemethodological choices and the nature of the hypotheses andmodels being tested. As the examples of the preceding sectionillustrate, the view that heuristics and biases are only studiedand found in the laboratory is a caricature.1Similarly, theRPD model could have emerged from the laboratory, and ithas been tested there (Johnson & Raab, 2003; Klein, Wolf,Militello, & Zsambok, 1995). In addition, a number of NDMresearchers have reported studies of the performance of pro-\ufb01cient decision makers in realistically simulated environments(e.g., Smith, Gif\ufb01n, Rockwell, & Thomas, 1986).1Among many other examples, see Slovic (2000) for applications tothe study of responses to risk; Guthrie, Rachlinski, and Wistrich (2007)and Sunstein (2000) for applications in the legal domain; Croskerry andNorman (2008) for medical judgment; Bazerman (2005) for managerialjudgments and decision making; and Kahneman and Renshon (2007) forpolitical decision making. The collection assembled by Gilovich, Grif\ufb01n,and Kahneman (2002) includes other examples.518 September 2009\u25cfAmerican PsychologistThe Definition of ExpertiseNDM researchers cannot use the same kinds of optimalitycriteria as the HB community to de\ufb01ne expertise. In rarecases (e.g., the ratings of chess players based on theirrecord of wins and losses against other rated players) theperformance level of experts is determined using standard-ized measures. However, in most of the situations studiedby NDM researchers, the criteria for judging expertise arebased on a history of successful outcomes rather than onquantitative performance measures. The most commonmethod for de\ufb01ning expertise in NDM research is to rely onpeer judgments. The conditions for de\ufb01ning expertise arethe existence of a consensus and evidence that the consen-sus re\ufb02ects aspects of successful performance that areobjective even if they are not quanti\ufb01ed explicitly. If theperformance of different professionals can be compared,the best practitioners de\ufb01ne the standard. As Shanteau(1992) suggested, \u201cExperts are operationally de\ufb01ned asthose who have been recognized within their profession ashaving the necessary skills and abilities to perform at thehighest level\u201d (p. 255). For example, captains of \ufb01re\ufb01ght-ing companies are evaluated not only by their ability toextinguish \ufb01res, but also by other criteria, such as theamount of damage created before the \ufb01re is controlled.When colleagues say, \u201cIf Person X had been there insteadof Person Y, the \ufb01re would not have spread as far,\u201d thenPerson X counts as an expert within that organization. Theuse of peer judgments can distinguish highly competentdecision makers from mediocre ones who may have thesame amount of experience and from novices who havelittle experience. This level of differentiation is suf\ufb01cientfor most NDM studies.In several of the studies that Meehl (1954) reviewed,the quality of expert performance was evaluated by com-paring the accuracy of decisions made by experts with theaccuracy of optimal linear combinations. If the predictionsgenerated by a linear combination of a few variables aremore accurate (in a new sample) than those of a profes-sional who has access to the same information, the perfor-mance of the professional is certainly suboptimal. Note thatthe optimality criterion is signi\ufb01cantly more demandingthan the criteria by which expertise is evaluated in NDMresearch. NDM researchers compare the performance ofprofessionals with that of the most successful experts intheir \ufb01eld, whereas HB researchers prefer to compare thejudgments of professionals with the outcome of a modelthat makes the best possible use of available information. Itis entirely possible for the predictions of experienced cli-nicians to be superior to those of novices but inferior to alinear model or an intelligent system.Sources of IntuitionThe judgments and decisions that we are most likely to callintuitive come to mind on their own, without explicitawareness of the evoking cues and of course without anexplicit evaluation of the validity of these cues. The \ufb01re-\ufb01ghter feels that the house is very dangerous, the nursefeels that an infant is ill, and the chess master immediatelysees a promising move. Intuitive skills are not restricted toprofessionals: Anyone can recognize tension or fatigue in afamiliar voice on the phone. In the language of the two-system (or dual process) models that have recently becomepopular (Evans & Frankish, 2009; see Evans, 2007, for areview of the origins of these ideas), intuitive judgmentsare produced by \u201cSystem 1 operations,\u201d which are auto-matic, involuntary, and almost effortless. In contrast, thedeliberate activities of System 2 are controlled, voluntary,and effortful\u2014they impose demands on limited attentionalresources. System 2 is involved, for example, when oneperforms a calculation (17/H1100324/H11005?), completes a taxform, reads a map, makes a left turn into heavy traf\ufb01c, orparks in a narrow space. Self-monitoring is also a System2 operation, which is impaired by concurrent effortfultasks.The distinction between Systems 1 and 2 plays animportant role in both the HB and NDM approaches. In theRPD model, for example, the performance of experts in-volves both an automatic process that brings promisingsolutions to mind and a deliberate activity in which theexecution of the candidate solution is mentally simulated ina process of progressive deepening. In the HB approach,System 2 is involved in the effortful performance of somereasoning and decision-making tasks as well as in thecontinuous monitoring of the quality of reasoning. Whenthere are cues that an intuitive judgment could be wrong,System 2 can impose a different strategy, replacing intu-ition by careful reasoning.2The NDM and HB approaches share the assumptionthat intuitive judgments and preferences have the charac-teristics of System 1 activity: They are automatic, ariseeffortlessly, and often come to mind without immediatejusti\ufb01cation. However, the two approaches focus on differ-ent classes of intuition. Intuitive judgments that arise fromexperience and manifest skill are the province of NDM,which explores the cues that guided such judgments and theconditions for the acquisition of skill. In contrast, HBresearchers have been mainly concerned with intuitivejudgments that arise from simplifying heuristics, not fromspeci\ufb01c experience. These intuitive judgments are lesslikely to be accurate and are prone to systematic biases.We discuss the two classes of judgment in sequence.First, we describe the process of skill acquisition thatsupports the intuitive judgments and preferences of genuineexperts. In particular, we explore two necessary conditionsfor the development of skill: high-validity environmentsand an adequate opportunity to learn them. Next, we dis-cuss heuristic-based intuitions and some of the biases towhich they are prone. Finally, we address the question ofthe critique of intuition: How can skilled intuitions bedistinguished from heuristic-based intuitions?2The contrast between System 1 and System 2 has given rise to itsown literature. For example, J. St. B. T. Evans (2007) has asserted thatSystem 1 is affected by the tendency to contextualize problems in the lightof prior knowledge and belief and that System 2 is affected by thetendency to satis\ufb01ce without considering alternatives.519September 2009\u25cfAmerican PsychologistSkilled Intuition as RecognitionSimon (1992) offered a concise de\ufb01nition of skilled intu-ition that we both endorse: \u201cThe situation has provided acue: This cue has given the expert access to informationstored in memory, and the information provides the answer.Intuition is nothing more and nothing less than recognition\u201d(p. 155). The model of intuition as recognition is helpful inseveral ways. First, it demysti\ufb01es intuition. Many expertswho have intuitions (and some authors who study them)endow intuition with an almost magic aura\u2014knowledgethat is not acquired by a rational process. In Simon\u2019sde\ufb01nition, the process by which the pediatric nurse recog-nizes that an infant may be gravely ill is not different inprinciple from the process by which she would notice thata friend looks tired or angry or from the way in which asmall child recognizes that an animal is a dog, not a cat. Itmay be worth noting that this description of pattern recog-nition and the skilled pattern recognition described in theRPD model are different from the recognition heuristicdiscussed by Goldstein and Gigerenzer (1999), which is aspecial-purpose rule of thumb.The recognition model implies two conditions thatmust be satis\ufb01ed for an intuitive judgment (recognition) tobe genuinely skilled: First, the environment must provideadequately valid cues to the nature of the situation. Second,people must have an opportunity to learn the relevant cues.For the \ufb01rst condition, valid cues must be speci\ufb01able, atleast in principle\u2014even if the individual does not knowwhat they are. The child relies on valid cues to identify adog, without any ability to state what the cues are. Simi-larly, the nurse and the \ufb01re\ufb01ghter are also guided by validcues they \ufb01nd in the environment. No magic is involved. Acrucial conclusion emerges: Skilled intuitions will onlydevelop in an environment of suf\ufb01cient regularity, whichprovides valid cues to the situation. The ways in whichskilled judgments take advantage of environmental regu-larities have been discussed by, among others, Brunswik(1957) and Hertwig, Hoffrage, and Martingnon (1999).Validity, as we use the term, describes the causal andstatistical structure of the relevant environment. For exam-ple, it is very likely that there are early indications that abuilding is about to collapse in a \ufb01re or that an infant willsoon show obvious symptoms of infection. On the otherhand, it is unlikely that there is publicly available informa-tion that could be used to predict how well a particularstock will do\u2014if such valid information existed, the priceof the stock would already re\ufb02ect it. Thus, we have morereason to trust the intuition of an experienced \ufb01regroundcommander about the stability of a building, or the intui-tions of a nurse about an infant, than to trust the intuitionsof a trader about a stock. We can con\ufb01dently expect that adetailed study of how professionals think is more likely toreveal useful predictive cues in the former cases than in thelatter.Determining the validity of an environment is notalways easy. When Tetlock (2005) embarked on his ambi-tious study of long-term forecasts of strategic and eco-nomic events by experts, the outcome of his research wasnot obvious. Fifteen years later it was quite clear that thehighly educated and experienced experts that he studiedwere not superior to untrained readers of newspapers intheir ability to make accurate long-term forecasts of polit-ical events. The depressing consistency of the experts\u2019failure to outdo the novices in this task suggests that theproblem is in the environment: Long-term forecasting mustfail because large-scale historical developments are toocomplex to be forecast. The task is simply impossible. Athought experiment can help. Consider what the history ofthe 20th century might have been if the three fertilized eggsthat became Hitler, Stalin, and Mao had been female. Thecentury would surely have been very different, but can oneknow how?In other environments, the regularities that can beobserved are misleading. Hogarth (2001) introduced theuseful notion of wicked environments, in which wrongintuitions are likely to develop. His most compelling ex-ample (borrowed from Lewis Thomas) is the early 20th-century physician who frequently had intuitions about pa-tients in the ward who were about to develop typhoid. Hecon\ufb01rmed his intuitions by palpating these patients\u2019tongues, but because he did not wash his hands the intui-tions were disastrously self-ful\ufb01lling.High validity does not imply the absence of uncer-tainty, and the regularities that are to be discovered aresometimes statistical. Games such as bridge or poker countas high-validity situations. The mark of these situations isthat skill, the ability to identify favorable bets, improveswithout guaranteeing that every attempt will succeed. Thechallenge of learning bridge and poker is not essentiallydifferent from the challenge of learning chess, where theuncertainty arises from the enormous number of possibledevelopments.As the examples of competitive games illustrate, thesecond necessary condition for the development of recog-nition (and of skilled intuition) is an adequate opportunityto learn the relevant cues. It has been estimated that chessmasters must invest 10,000 hours to acquire their skills(Chase & Simon, 1973). Fortunately, most of the skills canbe acquired with less practice. A child does not needthousands of examples to learn to discriminate dogs fromcats. The skilled pediatric nurse has seen a suf\ufb01cient num-ber of sick infants to recognize subtle signs of disease, andthe experienced \ufb01reground commander has experiencednumerous \ufb01res and probably imagined many more, duringyears of thinking and conversing about \ufb01re\ufb01ghting. With-out these opportunities to learn, a valid intuition can onlybe due to a lucky accident or to magic\u2014and we do notbelieve in magic.Two conditions must be satis\ufb01ed for skilled intuitionto develop: an environment of suf\ufb01ciently high validity andadequate opportunity to practice the skill. Ericsson, Char-ness, Hoffman, and Feltovich (2006) have described arange of factors that in\ufb02uence the rate of skill development.These include the type of practice people employ, theirlevel of engagement and motivation, and the self-regula-tory processes they use. Even when the circumstances arefavorable, however, some people will develop skilled in-520 September 2009\u25cfAmerican Psychologisttuitions more quickly than others. Talent surely matters.Every normal child can recognize a cat or a dog, but not alldedicated chess players become grand masters. Extraordi-nary players such as Fischer and Kasparov were able torecognize patterns that other grand masters could not see ontheir own\u2014although the weaker players could recognizethe validity of the star\u2019s intuition when led through it.Intuitions that are available only to a few exceptionalindividuals are often called creative. Like other intuitions,however, creative intuitions are based on \ufb01nding validpatterns in memory, a task that some people perform muchbetter than others. There are large individual differences inperformance on the Remote Associations Test (RAT),which has a long history as a test of creativity. Participantsin that test are instructed to search for a common associateof three words. The task has a wide range of dif\ufb01culty: Theitem cottage/swiss/cake is easy, but few people can quickly\ufb01nd the answer to the item dive/light/rocket\u2014althougheveryone recognizes the answer as valid (it is above us andis blue in good weather; Mednick, 1962). The RAT bringsus back to Simon\u2019s observation that the regularities onwhich intuitions depend are represented in memory. Thesituation of the RAT has high validity: Widely sharedpatterns of associations exist, which everyone can recog-nize although few can \ufb01nd them without prompting.Imperfect IntuitionWe have seen that reliably skilled intuitions are likely todevelop when the individual operates in a high-validityenvironment and has an opportunity to learn the rules ofthat environment. These conditions often remain unmet inprofessional contexts, either because the environment isinsuf\ufb01ciently predictable (as in the long-term forecasting ofpolitical events) or because of the absence of opportunitiesto learn its rules (as in the case of \ufb01re\ufb01ghters exposed to a\ufb01re in a skyscraper with unexpected damage to the heatshielding of its structural support). We both agree that mostof the intuitive judgments and decisions that System 1produces are skilled, appropriate, and eventually success-ful. But we also agree that not all intuitive judgments areskilled, although our hunches about the frequency of ex-ceptions differ. People, including experienced profession-als, sometimes have subjectively compelling intuitionseven when they lack true skill, either because the environ-ment is insuf\ufb01ciently regular or because they have notmastered it. Lewis (2003) described the weaknesses in theability of baseball scouts and managers to judge the capa-bilities, contributions, and potential of players. Despiteample opportunities to acquire judgment skill, scouts andmanagers were often insensitive to important variables andoverly in\ufb02uenced by such factors as the player\u2019s appear-ance\u2014a clear case of prediction by representativeness.When intuitive judgments do not come from skill,where do they come from? This is the question that stu-dents of heuristics and biases have explored, mostly inlaboratory experiments. The answer, of course, is thatincorrect intuitions, like valid ones, also arise from theoperations of memory. Three phenomena that have beendiscussed in the HB literature illustrate the sources of\ufb02awed intuitive judgments.Frederick (2005) has studied problems such as thefollowing: \u201cA ball and a bat together cost $1.10. The batcosts a dollar more than the ball. How much does the ballcost?\u201d The question invariably evokes an immediate tenta-tive solution: 10 cents. But the intuitive response is wrongin this problem: The correct response is 5 cents. Further-more, an easy check will quickly show that the answer iswrong: If the ball is worth 10 cents, then the bat is worth$1.10 and the total is $1.20, which is not correct. Thesurprising \ufb01nding of Frederick\u2019s research is that manyintelligent people adopt the intuitively compelling responsewithout checking it. The incidence of intuitive errors in thisquestion ranges from approximately 50% in top undergrad-uate schools (MIT, Princeton, Harvard) to 90% in some-what less selective schools. It can be argued that the settingof this problem is not typical of the challenges that peopleface in the real world, but the phenomenon that Frederickstudied is hardly restricted to puzzles. A common genre ofbusiness literature celebrates successful leaders who madestrategic decisions on the basis of gut feelings and intui-tions that they did not adequately check, but many of thesesuccesses owe more to luck than to genius (Rosenzweig,2007).The anchoring phenomenon is another case in which abias in the operations of memory causes intuitions to goastray. Suppose some participants in an experiment are \ufb01rstasked \u201cIs the average price of German cars more or lessthan $100,000?\u201d before they are required to provide anumerical estimate of the average cost of German cars.Other respondents encounter a different anchoring ques-tion: They are \ufb01rst asked whether the average cost ofGerman cars is more or less than $30,000, and then they areto give an estimate of the average. We can expect theestimates of the two groups to differ by as much as half thedifference between the anchors\u2014in this case the expectedanchoring effect would be $35,000 (Jacowitz & Kahneman,1995). The mechanism of anchoring is well understood(Mussweiler & Strack, 2000). The original question withthe high anchor brings expensive cars to the respondents\u2019mind: Mercedes, BMWs, Audis. The lower anchor is morelikely to evoke the image of a beetle and the name Volks-wagen. The initial question therefore biases the sample ofcars that come to mind when people next attempt to esti-mate the average price of German cars. The process ofestimating the average is a deliberate, System 2 operation,but the bias occurs in the automatic phase in which in-stances are retrieved from memory. The resulting anchor-ing effect is large and robust. The answers that come tomind are typically held with substantial con\ufb01dence, and thevictims of anchoring manipulations con\ufb01dently deny anyeffect of the anchor. The common criticism of laboratoryexperiments hardly applies here, because large anchoringeffects have been demonstrated in the courtroom, in realestate transactions, and in other real-world contexts.For a \ufb01nal example, consider this question: \u201cJulie is agraduating senior. She read \ufb02uently at age 4. What is yourbest guess of her GPA [grade point average]?\u201d Most people521September 2009\u25cfAmerican Psychologistwho think about this question report having an immediateintuitive impression of the best-\ufb01tting GPA. The value thatcomes to their mind is a GPA that is as impressive asJulie\u2019s precocity in reading\u2014roughly a match of percentilescores. This intuitive prediction is clearly wrong because itis not regressive. The correlation between early reading andgraduating GPA is not high and certainly does not justifynonregressive matching. The process that generates thisintuitive answer has been called attribute substitution. Theattribute that is to be assessed is GPA, but the answer issimply a projection onto the GPA scale of an evaluation ofreading precocity. Attribute substitution has been describedas an automatic process. It produces intuitive judgments inwhich a dif\ufb01cult question is answered by substituting aneasier one\u2014the essence of heuristic thinking (Kahneman &Frederick, 2002).Of course, the mechanisms that produce incorrectintuitions will only operate in the absence of skill. If peoplehave a skilled response to the task with which they arecharged, they will apply their skill. But even in the absenceof skill an intuitive response may come to their minds. Thedif\ufb01culty is that people have no way to know where theirintuitions came from. There is no subjective marker thatdistinguishes correct intuitions from intuitions that are pro-duced by highly imperfect heuristics. An important char-acteristic of intuitive judgments, which they share withperceptual impressions, is that a single response initiallycomes to mind. Most of the time we have to trust this \ufb01rstimpulse, and most of the time we are right or are able tomake the necessary corrections if we turn out to be wrong,but high subjective con\ufb01dence is not a good indication ofvalidity (Einhorn & Hogarth, 1978). Checking one\u2019s intu-ition is an effortful operation of System 2, which people donot always perform\u2014sometimes because it is dif\ufb01cult to doso and sometimes because they do not bother.Intuitions that originate in heuristics are not necessar-ily wrong. Indeed, the original statement of the HB ap-proach asserted, \u201cIn general these heuristics are quite use-ful, but sometimes they lead to severe and systematicerrors\u201d (Tversky & Kahneman, 1974, p. 1124). The HBclaim is not that intuitions that arise in heuristics are alwaysincorrect, only that they are less trustworthy than intuitionsthat are rooted in speci\ufb01c experiences. Unfortunately, peo-ple are not normally aware of the origins of the thoughtsthat come to their minds, and the correlation between theaccuracy of their judgments and the con\ufb01dence they expe-rience is not consistently high (Arkes, 2001; Grif\ufb01n &Tversky, 1992). Subjective con\ufb01dence is often determinedby the internal consistency of the information on which ajudgment is based, rather than by the quality of that infor-mation (Einhorn & Hogarth, 1978; Kahneman & Tversky,1973). As a result, evidence that is both redundant and\ufb02imsy tends to produce judgments that are held with toomuch con\ufb01dence. These judgments will be presented tooassertively to others and are likely to be believed more thanthey deserve to be. The safe way to evaluate the probableaccuracy of a judgment (our own or someone else\u2019s) is byconsidering the validity of the environment in which thejudgment was made as well as the judge\u2019s history oflearning the rules of that environment.Professional IntuitionsWe are of course not the \ufb01rst to have identi\ufb01ed a regularenvironment and an adequate opportunity to learn it aspreconditions for the development of skills, including in-tuitive skills (see, e.g., Hogarth, 2001). Other investigatorshave focused on attitude, motivation, talent, and deliberatepractice as crucial to skill development (Ericsson, 2006;Ericsson et al., 2006).The importance of predictable environments and op-portunities to learn them was apparent in an early review ofprofessions in which expertise develops. Shanteau (1992)reviewed evidence showing that expertise was found inlivestock judges, astronomers, test pilots, soil judges, chessmasters, physicists, mathematicians, accountants, grain in-spectors, photo interpreters, and insurance analysts. In con-trast, Shanteau noted poor performance by experiencedprofessionals in another large set of occupations: stockbro-kers, clinical psychologists, psychiatrists, college admis-sions of\ufb01cers, court judges, personnel selectors, and intel-ligence analysts. Shanteau searched for task characteristicsthat distinguished the domains in which experts did wellfrom those in which experts did poorly. The factors that weidenti\ufb01ed\u2014the predictability of outcomes, the amount ofexperience, and the availability of good feedback\u2014wereincluded in his list. In addition, Shanteau pointed to static(as opposed to dynamic) stimuli as favorable to goodperformance.Three professions\u2014nurses, physicians, and audi-tors\u2014appeared on both of Shanteau\u2019s (1992) lists. Theseprofessionals exhibited genuine expertise in some of theiractivities but not in others. We refer to such mixed gradesfor professionals as \u201cfractionated expertise,\u201d and we be-lieve that the fractionation of expertise is the rule, not anexception. For example, auditors who have expertise in\u201chard\u201d data such as accounts receivable may do much lesswell with \u201csoft\u201d data such as indications of fraud (J. Shan-teau, personal communication, February 12, 2009).There are a few activities, such as chess, in which amaster will not encounter challenges that are genuinelynew. In most domains, however, professionals will occa-sionally have to deal with situations and tasks that theyhave not had an opportunity to master. Physicians, as iswell known, encounter from time to time diagnostic prob-lems that are entirely new to them\u2014they have expertise insome diagnoses but not in others. Similarly, weather fore-casters are more successful in the routine prediction oftemperature and precipitation than in forecasting hail(Stewart, Roebber, & Bosart, 1997).Characteristically, we came to the topic of fraction-ated expertise with different examples in mind. GK focuseson the experts who perform a constant task (e.g., puttingout \ufb01res; establishing a diagnosis) but encounter unfamiliarsituations. The ability to recognize that a situation is anom-alous and poses a novel challenge is one of the manifesta-tions of authentic expertise. Descriptions of diagnosticthinking in medicine emphasize the intuitive ability of522 September 2009\u25cfAmerican Psychologistsome physicians to realize that the characteristics of a casedo not \ufb01t into any familiar category and call for a deliberatesearch for the true diagnosis (Gawande, 2002; Groopman,2007).DK is particularly interested in cases in which profes-sionals who know how to use their knowledge for somepurposes attempt to use the same knowledge for otherpurposes. He views the fractionation of expertise as oneelement in the explanation of the illusion of validity: theovercon\ufb01dence that professionals sometimes experience indealing with problems in which they have little or no skill.Finance professionals, psychotherapists, and intelligenceanalysts may know a great deal about a particular company,patient, or international con\ufb02ict, and they may have re-ceived ample feedback supporting their con\ufb01dence in theperformance of some tasks\u2014typically those that deal withthe short term\u2014but the feedback they receive from theirfailures in long-term judgments is delayed, sparse, andambiguous. The experience of the professionals that DKhas thought about is therefore conducive to overcon\ufb01dence.These professionals may have strong subjective con-\ufb01dence in their judgments, but we do not believe thatsubjective con\ufb01dence reliably indicates whether intuitivejudgments or decisions are valid. When experts recognizeanomalies, using judgments of typicality and familiarity,they are detecting violations of patterns in theexternalsituation. In contrast, people do not have a strong ability todistinguish correct intuitions from faulty ones. People, evenexperts, do not appear to be skilled in detecting patterns intheinternalsituation in order to identify the basis for theirjudgments. Therefore, reliance on subjective con\ufb01dencemay contribute to overcon\ufb01dence.The experts that GK has studied seem less susceptibleto overcon\ufb01dence, perhaps in part because of the directpersonal risks it poses. Weather forecasters, engineers, andlogistics specialists typically resist requests to make judg-ments about matters that fall outside their area of compe-tence. People in professions marked by standard methods,clear feedback, and direct consequences for error appear toappreciate the boundaries of their expertise. These expertsknow more knowledgeable experts exist. Weather forecast-ers know there are people in another location who betterunderstand the local dynamics. Structural engineers knowthat chemical engineers, or even structural engineers work-ing with different types of models or materials, are the trueexperts who should be consulted.As in the other topics that we have considered, we \ufb01ndno reason to disagree about either fractionation of expertiseor overcon\ufb01dence. As usual, different rules apply to dif-ferent tasks.Augmenting Professional Judgment:The Use of AlgorithmsThe attitude toward the Meehl paradigm, in which intui-tions and professional judgments are set in competition, isa sore point in conversations between adherents of NDMand HB. The idea of algorithms that outdo human judges isa source of pride and joy for members of the HB tribe, butalgorithms are usually distrusted by the NDM community.There is compelling evidence that under certain con-ditions mechanical and analytical judgments outperformhuman judgment. Grove, Zald, Lebow, Snitz, and Nelson(2000) reported a meta-analysis of 136 studies that com-pared the accuracy of clinical and mechanical judgments,most within the domains of clinical psychology and med-icine. Their review excluded studies involving nonhumanoutcomes such as horse races and weather. The preponder-ance of data favored the algorithms (i.e., the \u201cmechanical\u201djudgments), which were superior in about half the studies(n/H1100563). The other half of the studies showed no differ-ence (n/H1100565), and only a few studies showed betterperformance by the clinical judgments (n/H110058). For exam-ple, the tasks for which there was at least a 17-pointdifference in effect size favoring mechanical over clinicaljudgments included the following: college academic per-formance, presence of throat infections, diagnosis of gas-trointestinal disorders, length of psychiatric hospitalization,job turnover, suicide attempts, juvenile delinquency, ma-lingering, and occupational choice.Findings in which the performance of human judges isinferior to that of simple algorithms are often cited asevidence of cognitive ineptitude, but this conclusion isunwarranted. The correct conclusion is that people performsigni\ufb01cantly more poorly than algorithmsin low-validityenvironments. The tasks reviewed by Grove et al. (2000)generally involved noisy and/or highly complex situations.The forecasts made by the algorithms were often wrong,albeit less often than the clinical predictions. The studies inthe Meehl paradigm have not produced \u201csmoking gun\u201ddemonstrations in which clinicians miss highly valid cuesthat the algorithm detects and uses. Indeed, such an out-come would be unlikely, because human learning is nor-mally quite ef\ufb01cient. Where simple and valid cues exist,humans will \ufb01nd them if they are given suf\ufb01cient experi-ence and enough rapid feedback to do so\u2014except in theenvironments that Hogarth (2001) labeled \u201cwicked,\u201d inwhich the feedback is misleading. A statistical approachhas two crucial advantages over human judgment whenavailable cues are weak and uncertain: Statistical analysisis more likely to identify weakly valid cues, and a predic-tion algorithm will maintain above-chance accuracy byusing such cues consistently. The meta-analysis performedby Karelaia and Hogarth (2008) showed that consistencyaccounted for much of the advantage of algorithms overhumans.The evaluation and approval of personal loans by loanof\ufb01cers is an example of a situation in which algorithmsshould be used to replace human judgment. Identifying therelatively small number of defaulting loans is a low-valid-ity task because of the low base rate of the critical outcome.Algorithms have largely replaced human judges in thistask, using as inputs objective demographic and personaldata rather than subjective impression of reliability. Theresult is an unequivocal improvement: We have fairer loanjudgments (i.e., judgments that are not improperly in\ufb02u-enced by gender or race), faster decisions, and reducedexpenses.523September 2009\u25cfAmerican PsychologistOur analysis suggests that algorithms signi\ufb01cantlyoutperform humans under two quite different conditions:(a) when validity is so low that human dif\ufb01culties indetecting weak regularities and in maintaining consistencyof judgment are critical and (b) when validity is very high,in highly predictable environments, where ceiling effectsare encountered and occasional lapses of attention cancause humans to fail. Automatic transportation systems inairports are an example in that class.NDM proponents correctly emphasize that the condi-tions necessary for the construction and use of an algorithmare stringent. These conditions include (a) con\ufb01dence in theadequacy of the list of variables that will be used, (b) areliable and measurable criterion, (c) a body of similarcases, (d) a cost/bene\ufb01t ratio that warrants the investmentin the algorithmic approach, and (e) a low likelihood thatchanging conditions will render the algorithm obsolete. Wealso agree that algorithms that substitute for human judg-ment must remain under human supervision, to providecontinuous monitoring of their performance and of relevantchanges in the environment. Maintaining adequate super-vision of algorithms can be dif\ufb01cult, because there is evi-dence that human operators become more passive and lessvigilant when algorithms are in charge\u2014a phenomenonthat has been labeled \u201cautomation bias\u201d (Skitka, Mosier &Burdick, 1999, 2000).We agree that the introduction of algorithms and otherformal decision aids in organizations will often encounteropposition and unexpected problems of implementation.Few people enjoy being replaced by mechanical devices orby mathematical algorithms, and many devices and algo-rithms function less well in the real world than on theplanning board (Yates, Veinott, & Patalano, 2003). Evendecision aids and procedures that leave the authority of thedecision maker intact\u2014decision analysis is a salient exam-ple\u2014are often resisted, for both good and bad reasons.Naturally, we have somewhat different attitudes towardthese problems of implementation, with DK usually view-ing them as obstacles to be overcome and GK seeing themas reasons to be skeptical about the value of formal methods.Despite our different attitudes toward formal methods,we agree on the potential of semi-formal strategies. Anexample is the premortem method (Klein, 2007) for reduc-ing overcon\ufb01dence and improving decisions. Project teamsusing this method start by describing their plan. Next theyimagine that their plan has failed and the project has beena disaster. Their task is to write down, in two minutes, allthe reasons why the project failed. The facilitator goesaround the table, getting reasons from each of the teammembers, starting with the leader. The rationale for themethod is the concept of prospective hindsight (Mitchell,Russo, & Pennington, 1989)\u2014that people can generatemore criticisms when they are told that an outcome iscertain. It also offers a solution to one of the major prob-lems of decision making within organizations: the gradualsuppression of dissenting opinions, doubts, and objections,which is typically observed as an organization commitsitself to a major plan. The premortem method is consistentwith the HB concern for overcon\ufb01dence while drawing onand respecting the expertise of decision makers, a hallmarkof the NDM approach. We expect that there are additionalmethods that can synthesize the strengths of the two traditions.ConclusionsIn an effort that spanned several years, we attempted toanswer one basic question: Under what conditions are theintuitions of professionals worthy of trust? We do not claimthat the conclusions we reached are surprising (many wereanticipated by Shanteau, 1992, Hogarth, 2001, and Myers,2002, among others), but we believe that they add up to acoherent view of expert intuition, which is more than weexpected to achieve when we began.\u25cfOur starting point is that intuitive judgments canarise from genuine skill\u2014the focus of the NDMapproach\u2014but that they can also arise from inap-propriate application of the heuristic processes onwhich students of the HB tradition have focused.\u25cfSkilled judges are often unaware of the cues thatguide them, and individuals whose intuitions are notskilled are even less likely to know where theirjudgments come from.\u25cfTrue experts, it is said, know when they don\u2019t know.However, nonexperts (whether or not they thinkthey are) certainly do not know when they don\u2019tknow. Subjective con\ufb01dence is therefore an unreli-able indication of the validity of intuitive judgmentsand decisions.\u25cfThe determination of whether intuitive judgmentscan be trusted requires an examination of the envi-ronment in which the judgment is made and of theopportunity that the judge has had to learn theregularities of that environment.\u25cfWe describe task environments as \u201chigh-validity\u201d ifthere are stable relationships between objectively iden-ti\ufb01able cues and subsequent events or between cuesand the outcomes of possible actions. Medicine and\ufb01re\ufb01ghting are practiced in environments of fairlyhigh validity. In contrast, outcomes are effectivelyunpredictable in zero-validity environments. To agood approximation, predictions of the future value ofindividual stocks and long-term forecasts of politicalevents are made in a zero-validity environment.\u25cfValidity and uncertainty are not incompatible. Someenvironments are both highly valid and substan-tially uncertain. Poker and warfare are examples.The best moves in such situations reliably increasethe potential for success.\u25cfAn environment of high validity is a necessarycondition for the development of skilled intuitions.Other necessary conditions include adequate oppor-tunities for learning the environment (prolongedpractice and feedback that is both rapid and un-equivocal). If an environment provides valid cuesand good feedback, skill and expert intuition willeventually develop in individuals of suf\ufb01cient talent.\u25cfAlthough true skill cannot develop in irregular orunpredictable environments, individuals will some-524 September 2009\u25cfAmerican Psychologisttimes make judgments and decisions that are suc-cessful by chance. These \u201clucky\u201d individuals will besusceptible to an illusion of skill and to overcon\ufb01-dence (Arkes, 2001). The \ufb01nancial industry is a richsource of examples.\u25cfThe situation that we have labeled fractionation ofskill is another source of overcon\ufb01dence. Profes-sionals who have expertise in some tasks are some-times called upon to make judgments in areas inwhich they have no real skill. (For example, \ufb01nan-cial analysts may be skilled at evaluating the likelycommercial success of a \ufb01rm, but this skill does notextend to the judgment of whether the stock of that\ufb01rm is underpriced.) It is dif\ufb01cult both for theprofessionals and for those who observe them todetermine the boundaries of their true expertise.\u25cfWe agree that the weak regularities available inlow-validity situations can sometimes support thedevelopment of algorithms that do better thanchance. These algorithms only achieve limited ac-curacy, but they outperform humans because oftheir advantage of consistency. However, the intro-duction of algorithms to replace human judgment islikely to evoke substantial resistance and sometimeshas undesirable side effects.Another conclusion that we both accept is that theapproaches of our respective communities have built-inlimitations. For historical and methodological reasons, HBresearchers generally \ufb01nd errors more interesting and in-structive than correct performance; but a psychology ofjudgment and decision making that ignores intuitive skill isseriously blinkered. Because their intellectual attitudes de-veloped in reaction to the HB tradition, members of theNDM community have an aversion to the wordbiasand tothe corresponding concept; but a psychology of profes-sional judgment that neglects predictable errors cannot beadequate. Although we agree with both of these conclu-sions, we have yet to move much beyond recognition of theproblem. DK is still fascinated by persistent errors, and GKstill recoils when biases are mentioned. We hope, however,that our effort may help others do more than we have beenable to do in bringing the insights of both communities tobear on their common subject.REFERENCESArkes, H. R. (2001). Overcon\ufb01dence in judgmental forecasting. In J. S.Armstrong (Ed.),Principles of forecasting: A handbook for researchersand practitioners(pp. 495\u2013516). Boston: Kluwer Academic.Bazerman, M. H. (2005).Judgment in managerial decision making(6thed.). Hoboken, NJ: Wiley.Beach, L. R. (1990).Image theory: Decision making in personal andorganizational contexts.Chichester, England: Wiley.Brunswik, E. (1957). Scope and aspects of the cognitive problem. In H.Gruber, K. R. Hammond, & R. Jessor (Eds.),Contemporary ap-proaches to cognition(pp. 5\u201331). Cambridge, MA: Harvard UniversityPress.Cannon-Bowers, J. A., & Salas, E. (Eds.). (1998).Making decisions understress: Implications for individual and team training.Washington, DC:American Psychological Association.Chase, W. G., & Simon, H. A. (1973). The mind\u2019s eye in chess. In W. G.Chase (Ed.),Visual information processing(pp. 215\u2013281). New York:Academic Press.Collyer, S. C., & Malecki, G. S. (1998). Tactical decision making understress: History and overview. In J. A. Cannon-Bowers & E. Salas(Eds.),Making decisions under stress: Implications for individual andteam training(pp. 3\u201315). Washington, DC: American PsychologicalAssociation.Crandall, B., & Gamblian, V. (1991).Guide to early sepsis assessment inthe NICU[Instruction manual prepared for the Ohio Department ofDevelopment under the Ohio Small Business Innovation ResearchBridge Grant program]. Fairborn, OH: Klein Associates.Crandall, B., & Getchell-Reiter, K. (1993). Critical decision method: Atechnique for eliciting concrete assessment indicators from the \u201cintu-ition\u201d of NICU nurses.Advances in Nursing Sciences, 16(1), 42\u201351.Crandall, B., Klein, G., & Hoffman, R. R. (2006).Working minds: Apractitioner\u2019s guide to cognitive task analysis.Cambridge, MA: MITPress.Croskerry, P., & Norman, G. (2008). Overcon\ufb01dence in clinical decisionmaking.The American Journal of Medicine, 121,S24\u2013S29.deGroot, A. D. (1978).Thought and choice in chess.The Hague: Mouton.(Original work published 1946)Einhorn, H. J., & Hogarth, R. M. (1978). Con\ufb01dence in judgment:Persistence of the illusion of validity.Psychological Review, 85,395\u2013416.Ericsson, K. A. (2006). The in\ufb02uence of experience and deliberate prac-tice on the development of superior expert performance. In K. A.Ericsson, N. Charness, R. R. Hoffman, & P. J. Feltovich (Eds.),TheCambridge handbook of expertise and expert performance(pp. 39\u201368).New York: Cambridge University Press.Ericsson, K. A., Charness, N., Hoffman, R. R., & Feltovich, P. J. (Eds.).(2006).The Cambridge handbook of expertise and expert performance.New York: Cambridge University Press.Evans, J. St. B. T. (2007).Hypothetical thinking: Dual processes inreasoning and judgment.Hove, East Sussex, England: PsychologyPress.Evans, J. St. B. T., & Frankish, K. (Eds.). (2009).In two minds: Dualprocesses and beyond.New York: Oxford University Press.Fogarty, W. M. (1988).Formal investigation into the circumstancessurrounding the downing of a commercial airliner by the U. S. S.Vincennes (CG 49) on 3 July 1988[Unclassi\ufb01ed Letter Ser. 1320 of 28July 1988, to Commander in Chief, U.S. Central Command]. Washing-ton, DC: U.S. Department of the Navy.Frederick, S. (2005). Cognitive re\ufb02ection and decision making.Journal ofEconomic Perspectives, 19(4), 25\u201342.Gawande, A. (2002).Complications: A surgeon\u2019s notes on an imperfectscience.London: Pro\ufb01le Books.Gilovich, T., Grif\ufb01n, D., & Kahneman, D. (Eds.). (2002).Heuristics andbiases: The psychology of intuitive judgment.New York: CambridgeUniversity Press.Goldberg, L. R. (1970). Man versus model of man: A rationale, plus someevidence, for a method of improving on clinical inferences.Psycholog-ical Bulletin, 73,422\u2013432.Goldstein, D. G., & Gigerenzer, G. (1999). The recognition heuristic:How ignorance makes us smart. In G. Gigerenzer, P. M. Todd, &A. B. C. Research Group (Eds.),Simple heuristics that make us smart(pp. 37\u201358). New York: Oxford University Press.Grif\ufb01n, D. W., & Tversky, A. (1992). The weighing of evidence and thedeterminants of con\ufb01dence.Cognitive Psychology, 24,411\u2013435.Groopman, J. (2007).How doctors think.New York: Houghton Mif\ufb02in.Grove, W. M., Zald, D. H., Lebow, B. S., Snitz, B. E., & Nelson, C.(2000). Clinical versus mechanical prediction: A meta-analysis.Psy-chological Assessment, 12,19\u201330.Guthrie, C., Rachlinski, J. J., & Wistrich, A. J. (2007). Blinking on thebench: How judges decide cases.Cornell Law Review, 93,1\u201343.Hammond, K. R., Hamm, R. M., Grassia, J., & Pearson, T. (1987). Directcomparison of the ef\ufb01cacy of intuitive and analytical cognition inexpert judgment.IEEE Transactions on Systems, Man, and Cybernet-ics, SMC-17(5), 753\u2013770.Hertwig, R., Hoffrage, U., & Martingnon, L. (1999). Quick estimation:Letting the environment do the work. In G. Gigerenzer, P. M. Todd, &A. B. C. Research Group (Eds.),Simple heuristics that make us smart(pp. 37\u201358). New York: Oxford University Press.525September 2009\u25cfAmerican PsychologistHogarth, R. M. (2001).Educating intuition.Chicago: University of Chi-cago Press.Jacowitz, K. E., & Kahneman, D. (1995). Measures of anchoring inestimation tasks.Personality and Social Psychology Bulletin, 21,1161\u20131166.Johnson, J. G., & Raab, M. (2003). Take the \ufb01rst: Option generation andresulting choices.Organizational Behavior and Human Decision Pro-cesses, 91(2), 215\u2013229.Kahneman, D. (2003). Autobiography. In T. Frangsmyr (Ed.),Les PrixNobel 2002[Nobel Prizes 2002]. Stockholm, Sweden: Almqvist &Wiksell International.Kahneman, D., & Frederick, S. (2002). Representativeness revisited:Attribute substitution in intuitive judgment. In T. Gilovich, D. Grif\ufb01n,& D. Kahneman (Eds.),Heuristics and biases: The psychology ofintuitive judgment(pp. 49\u201381). New York: Cambridge UniversityPress.Kahneman, D., & Renshon, J. (2007). Why hawks win.Foreign Policy,158,34\u201338.Kahneman, D., & Tversky, A. (1973). On the psychology of prediction.Psychological Review, 80,237\u2013251.Karelaia, N., & Hogarth, R. M. (2008). Determinants of linear judgment:A meta-analysis of lens model studies.Psychological Bulletin, 134,404\u2013426.Klein, G. A. (1993). A recognition-primed decision (RPD) model of rapiddecision making. In G. A. Klein, J. Orasanu, R. Calderwood, & C. E.Zsambok (Eds.),Decision making in action: Models and methods(pp.138\u2013147). Norwood, NJ: Ablex.Klein, G. (1998).Sources of power: How people make decisions.Cam-bridge, MA: MIT Press.Klein, G. (2007, September). Performing a project premortem.HarvardBusiness Review,pp. 18\u201319.Klein, G. A., Calderwood, R., & Clinton-Cirocco, A. (1986). Rapiddecision making on the \ufb01reground. InProceedings of the HumanFactors and Ergonomics Society 30th Annual Meeting(Vol. 1, pp.576\u2013580). Norwood, NJ: Ablex.Klein, G. A., Orasanu, J., Calderwood, R., & Zsambok, C. E. (1993).Decision making in action: Models and methods.Norwood, NJ: Ablex.Klein, G., Wolf, S., Militello, L., & Zsambok, C. (1995). Characteristicsof skilled option generation in chess.Organizational Behavior andHuman Decision Processes, 62,63\u201369.Lewis, M. (2003).Moneyball: The art of winning an unfair game.NewYork: Norton.Lipshitz, R. (1993). Converging themes in the study of decision making inrealistic settings. In G. A. Klein, J. Orasanu, R. Calderwood, & C. E.Zsambok (Eds.),Decision making in action: Models and methods(pp.103\u2013137). Norwood, NJ: Ablex.Mednick, S. A. (1962). The associative basis of the creative process.Psychological Review, 69,220\u2013232.Meehl, P. E. (1954).Clinical vs. statistical prediction: A theoreticalanalysis and a review of the evidence.Minneapolis: University ofMinnesota Press.Meehl, P. E. (1973). Why I do not attend case conferences. In P. E. Meehl(Ed.),Psychodiagnosis: Selected papers(pp. 225\u2013302). Minneapolis:University of Minnesota Press.Mitchell, D., Russo, J., & Pennington, N. (1989). Back to the future:Temporal perspective in the explanation of events.Journal of Behav-ioral Decision Making, 2,25\u201338.Montgomery, H. (1993). The search for a dominance structure in decisionmaking: Examining the evidence. In G. A. Klein, J. Orasanu, R.Calderwood, & C. E. Zsambok (Eds.),Decision making in action:Models and methods(pp. 182\u2013187). Norwood, NJ: Ablex.Mussweiler, T., & Strack, F. (2000). The use of category and exemplarknowledge in the solution of anchoring tasks.Journal of Personalityand Social Psychology, 78,1038\u20131052.Myers, D. G. (2002).Intuition: Its powers and perils.New Haven, CT:Yale University Press.Nisbett, R. E., & Wilson, T. D. (1977). Telling more than we can know:Verbal reports on mental processes.Psychological Review, 84,231\u2013259.Orasanu, J., & Connolly, T. (1993). The reinvention of decision making.In G. A. Klein, J. Orasanu, R. Calderwood, & C. E. Zsambok (Eds.),Decision making in action: Models and methods(pp. 3\u201320). Norwood,NJ: Ablex.Rasmussen, J. (1986).Information processing and human\u2013machine inter-action: An approach to cognitive engineering.Amsterdam: North-Holland.Rosenzweig, P. (2007).The halo effect . . . and the eight other businessdelusions that deceive managers.New York: Free Press.Schraagen, J. M. C., Chipman, S. F., & Shalin, V. J. (Eds.). (2000).Cognitive task analysis.Mahwah, NJ: Erlbaum.Shanteau, J. (1992). Competence in experts: The role of task character-istics.Organizational Behavior and Human Decision Processes, 53,252\u2013262.Simon, H. A. (1992). What is an explanation of behavior?PsychologicalScience, 3,150\u2013161.Skitka, L. J., Mosier, K., & Burdick, M. D. (1999). Does automation biasdecision-making?International Journal of Human\u2013Computer Studies,51,991\u20131006.Skitka, L. J., Mosier, K., & Burdick, M. D. (2000). Accountability andautomation bias.International Journal of Human\u2013Computer Studies,52,701\u2013717.Slovic, P. (Ed.). (2000).The perception of risk.London: Earthscan.Smith, P. J., Gif\ufb01n, W. C., Rockwell, T. H., & Thomas, M. (1986).Modeling fault diagnosis as the activation and use of a frame system.Human Factors, 28,703\u2013716.Stewart, T. R., Roebber, P. J., & Bosart, L. F. (1997). The importance ofthe task in analyzing expert judgment.Organizational Behavior andHuman Decision Processes, 69,205\u2013219.Sunstein, C. R. (Ed.). (2000).Behavioral law and economics.New York:Cambridge University Press.Tetlock, P. E. (2005).Expert political judgment: How good is it? How canwe know?Princeton, NJ: Princeton University Press.Tversky, A., & Kahneman, D. (1971). Belief in the law of small numbers.Psychological Bulletin, 76,105\u2013110.Tversky, A., & Kahneman, D. (1974). Judgment under uncertainty: Heu-ristics and biases.Science, 185,1124\u20131131.Woods, D. D., O\u2019Brien, J., & Hanes, L. F. (1987). Human factorschallenges in process control: The case of nuclear power plants. In G.Salvendy (Ed.),Handbook of human factors/ergonomics(pp. 1724\u20131770). New York: Wiley.Yates, J. F., Veinott, E. S., & Patalano, A. L. (2003). Hard decisions, baddecisions: On decision quality and decision aiding. In S. L. Schneider& J. C. Shanteau (Eds.),Emerging perspectives on judgment anddecision research(pp. 13\u201363). New York: Cambridge University Press.\n526 September 2009\u25cfAmerican Psychologist\nView publication stats"}], "max_tokens": 1000}}
